1. HTTP(无状态)常见状态码 及 常用的请求方式，区别和用途
    1. 1xx中间状态|
    - 100请求者应当继续提出请求
    - 101切换请求协议 如从HTTP切换到WebSocket
    2. 2xx请求成功|
    - 200请求成功
    - 204请求被受理但没有资源可以返回
    - 206客户端只是请求资源的一部分，服务器只对请求的部分资源执GET方法，相应报文中通过Content-Range指定范围的资源。
    3. 3xx重定位重新请求|
    > 301永久重定向 会缓存
    - 301 代表访问的地址的资源被永久移除了，以后都不应该访问这个地址，搜索引擎抓取的时候也会用新的地址替换这个老的。可以在返回的响应的 location 首部去获取到返回的地址。
    > 302临时重定向 
    - 这个资源只是暂时不能被访问了，但是之后过一段时间还是可以继续访问，一般是访问某个网站的资源需要权限时，会需要用户去登录，跳转到登录页面之后登录之后，还可以继续访问。
    - 303与302状态码有相似功能 它希望客户端在请求一个URL时 能通过GET方法重定向到另一个URI
    > 304
    - 协商缓存命中 
    > 307
    - 临时重定向 与302相似 只是强制要求使用POST请求
    4. 4xx请求报文错误|
    - 400参数校验失败 
    - 401未登录或token验证失败 
    - 402用户已禁用(禁止该用户)
    - 403禁止用户访问(禁止所有用户)
    - 404资源未找到 
    5. 5xx服务器端错误
    - 500服务端错误 
    - 503服务器正在忙
2. HTTP常见请求方式区别用途
    - GET：通用获取数据
    - POST：提交数据
    - DELETE：删除数据
    - CONNECT：建立连接隧道，用于代理服务器
    - PUT：修改数据
    - HEAD：获取资源的元信息
    - OPTIONS：列出可对资源实行的请求方法，常用于跨域    
3. get和post
    > 本质
    - 都是TCP连接 由于HTTP协议和浏览器或服务器限制 使其应用过程有所不同
    > 区别
    > get
        获取数据|参数有长度限制|url之后?分割url传输数据|多个参数用&连接|因读取数据 被浏览器主动缓存|参数被保存在浏览器中|产生一个TCP数据包 把HTTP Header和Data一起发送出去 服务器响应200|get数据明文传输|服务器端获取数据格式 application/json querystring
        13. get方式
    > 点击超链接/地址栏输入地址跳转页面 都是get方式
        get方式 传参 两种
        1.？+键值对(?blogid=3)
        3.命名传参 (:blogId)
    > post
        提交数据|参数无长度限制|数据放在http请求体|不会被浏览器主动缓存|参数不会被保存在浏览器中|产生一个TCP数据包 浏览器先发Http Header 服务器响应100 浏览器再发送Data 服务器响应200|post数据放在请求体 开发者可以抓包工具看到 也相当于明文|服务器端 application/x-www-urlencoded application/json querystring formdata
4. 四种常见的POST提交数据方式 和两种GET提交数据方式
    > HTTP/1.1协议 规定的HTTP请求方法有
    1. OPTIONS 
    2. GET 
    3. HEAD 
    4. POST 
    - POST一般用来向服务端提交数据
    5. PUT 
    6. DELETE 
    7. TRACE 
    8. CONNECT 这几种

    > HTTP协议是以ASCII码传输 建立在TCP/IP协议之上的应用层规范 规范把HTTP请求分为三部分
    1. 状态行    <method><request-URL><version>
    2. 请求头    <header>
    3. 消息主体  <entity-body>
    
5. application/json & application/x-www-formdata-urlencoded & multipart/form-data & text/xml
    - 协议规定POST提交数据必须放在消息主体(entity-body)中 但协议并没有规定数据必须使用什么编码格式
    - 实际上开发者完全可以自己决定消息主体的格式 只要最后发送的HTTP请求满足上面格式即可

    - 数据发送出去还要服务端解析成功才有意义 一般服务器语言如php python等 以及它们的framework都内置了自动解析常见数据格式的功能
    - 服务器端通常是根据请求头(headers)中Content-Type字段来获知请求中的消息主体是用何种方式编码 再对主体进行解析
    
    - 所以说到POST提交数据方案 包含Content-Type和消息主题编码方式两部分

    > form的Enctype属性--编码方式
    - 两种常用编码格式：
    1. application/x-www-form-urlencoded 默认
    2. multipart/form-data
    - action为get
        1. 浏览器用x-www-form-urlencoded编码方式把form数据转换成一个字符串(name1=value&name2=value2)
        2. 把这个字串 append到url后面 用?分割 加载这个新的url
    - 当action为post时
        1. 浏览器把form数据封装到http body中 然后发送到server
    - 如果没有type=file的控价 
        1. 用默认的application/x-www-form-urlencoded即可
    - 如果有type=file
        1. 用到multipart/form-data 浏览器会把整个表单以控件为单位分割 并为每个部分都加上 Content-Disposition(form-data/file) Content-Type(默认为text/plain) name(控件name)等信息 并加上分隔符(boundary)

    > application/x-www-form-urlencoded & multipart/form-data
    - (Form元素的Enctype属性指定了表单数据向服务器提交时所采用的编码类型)
    1. Form元素的Enctype属性指定了表单数据向服务器提交时所采用的编码类型 默认缺省值是application/x-www-form-urlencoded
    2. 向服务器发送大量文本 包含非ASCII字符的文本/二进制数据时这种编码方式效率很低
    3. 文件上载时 所使用的编码类型 应当 是 multipart/form-data 它既可以发送文本数据yy也支持二进制数据上传
    4. Browser端<form>表单的ENCTYPE属性值为multipart/form-data 它告诉我们传输的数据要用到多媒体传输协议 由于多媒体传输的都是大量数据 所以规定上传文件必须是post方法<input>的type属性必须是file

    1. application/x-www-form-urlencoded
        - 窗体数据被编码成名称/值对 这是标准的编码格式
    2. multipart/form-data
        - 窗体数据以纯文本形式机型编码 其中不含任何控件或格式字符
    3. text/plain：
        - 窗口数据以纯文本形式进行编码 其中不含任何控件或格式字符
   
    > 当action为get时
    - 浏览器用x-www-form-urlencoded编码方式把form数据转化成一个字符串(name1=value1&name2=value2&name3=value3)然后把这个字符串append到url后面 用?分割加载这个新的url
    > 当action为post时
    - 浏览器把form数据封装到http body中 然后发送到server 
    1. 如果没有type=file的控件 用默认的的application/x-www-form-urlencoded即可
    2. 如果有type=file 要用到multipart/form-data浏览器会把整个表单以控件为单位分割 并为每个部分加上Content-Disposition(form-data/file)Content-Type(默认为text/plain)name(控件name)等信息 并加上分割符(boundary)

    > Enctype属性
    > POST
    1. application/x-www-form-urlencoded
        - 最常见的post提交数据方式
        - 浏览器原生form表单 不设置ENCTYPE属性最终会以application/x-www-form-urlencoded方式提交数据
        - 很多时候 我们用AJAX提交数据时也是使用这种方式
        - 例如JQuery和QWrap的Ajax Content-Type默认值都是 application/x-www-form-urlencoded
    2. multipart/form-data
        - 一个常见的POST数据提交方式
        - 使用表单上传文件时 必须让form的ENCTYPE等于这个值
        - 这种方式一般用来上传文件 各大服务端语言对它也有良好的支持
        - PS:上面提到的这两种post数据的方式 都是浏览器原生支持的 而且现阶段原生form表单也只支持这两种方式 
        - 但是随着越来越多的Web站点 尤其是WebApp全部使用AJAX进行数据交互之后 我们完全可以定义新的数据提交方式 
    3. application/json
        - 把它当作请求头 用来告诉服务端消息主体是序列化后的JSON字符串 
        - 由于JSON规范的流行 除了低版本IE之外的各大浏览器都原生支持JSON.stringfy 
        - 服务端语言也都有处理JSON的函数使用JSON不会遇上什么麻烦 JSON格式支持比键值对复杂得多的结构化数据   
    4. text/xml
        - XML-RPC(XML Remote Procedure Call)它是一种使用HTTP作为传输协议XML作为编码方式的远程调用规范
        - XML-RPC协议简单 功能够用 各种语言的实现都有 它的使用也很广泛 如WordPress的XML-RPC API 搜索引擎的ping服务等
        - JS中 也有现成的库支持这种方式进行数据交互 能很好的支持已有的XML-RPC服务
    > GET
    1. application/json的发送和接收
        - 序列化后的JSON字符串
        - 客户端：
            - 发送JSON格式字符串'{"test":"I'm Client"}'
        - 服务端:
            1. 用file_get_contents拿到post数据 $_POST['test']取不到数据
            2. 然后使用json_decode解码 
            3. php中json访问方式 $json->test。php中没有{test:"I'm Client"}这种格式的，$json = {test:"I'm Client"}会报错。
            4. 返回数据时将数组json_encode编码。php中json格式没有，用数组代替。
    2. queryString   
6. TCP可靠传输 拥塞控制 流量控制
    > 可靠传输(有状态/可控制 流量控制)
    1. 有状态 TCP会确认发送了哪些报文/接收方收到了哪些报文保证数据包按序到达 不允许有差错/ --确认丢失和确认迟到
    2. 可控制(流量控制) 如出现丢包/网络状态不佳 则会跳转自己的行为 减少发送的速度或重发  --停止等待协议
    
    > (停止等待协议 可靠性/确认丢失和确认迟到 有状态)
    1. 停止等待协议 可靠性
    2. 确认丢失和确认迟到 有状态
    - PS:只要接收端没有告诉发送端收到了 发送端就认为接收端没有收到 发送端重传
    --------
    > TCP拥塞避免 
    - 作用于网络 防止过多数据注入网络 导致出现网络负载过大 
    > 四种算法 
    1. 慢启动机制
        - 新建TCP连接的时候 拥塞窗口以一个数据包大小(512B)为基数
        - 每接收一个ACK确认就会增加一个数据包发送量 这种增加呈指数增长
                    发送方维持一个叫做拥塞窗口cwnd的状态变量
            拥塞窗口的大小取决于网络的拥塞程度 并且在动态地变化
            发送方让自己的发送窗口等于拥塞窗口
            考虑到接收方的接收能力
            发送窗口可能小于拥塞窗口
            思路
                不要一开始就发送大量数据
                先检测一下网络拥塞程度
                即从小到大逐渐增加拥塞窗口大小
            一个传输轮次所经历的时间其实就是往返时间RTT 每经过一个传输轮次(transmission round)拥塞窗口cwnd就加倍
            防止cwnd(congestion window))增长过大引起网络拥塞 
            还需要设置一个
            慢开始门限ssthresh状态变量
            慢开始门限ssthresh用法:
                cwnd<ssthresh 慢开始算法
                cwnd>ssthresh 拥塞避免算法
                cwnd=ssthresh 慢开始算法 拥塞避免算法任意
            慢不是cwnd增长速率慢
            指TCP开始发送报文段时先设置cwnd=1
            然后逐渐增大 比按照大的cwnd一下子把许多报文段突然注入到网络中要慢得多
    2. 拥塞避免机制
        - 让拥塞窗口缓慢增大 每经过一个往返事件RTT
        - 发送方的拥塞窗口就加一 (CWND+1 注意不是加倍)此时CWND呈现线性增大
                    让拥塞窗口缓慢增长
            每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1 而不是加倍
            这样拥塞窗口 按线性规律缓慢增长
            无论满开始/拥塞避免阶段
            只要发送方判断网络出现堵塞
            (根据就是没有按时收到确认
            虽然没有收到确认可能是其他原因的分组丢失 但是因为无法判断 都当作拥塞来处理)
            就把慢开始门限ssthresh设置为拥塞时发送窗口大小的一般(但不能小于2)
            把拥塞窗口cwdn重置为1 执行慢开始算法
            目的 迅速减少主机发送到网络中得分组数
            使得发生拥塞得路由器有足够时间把队列中
            积压的分组处理完毕
            乘法减小和加法增大常合起来成为AIMD算法
            拥塞避免并非能完全避免阻塞 而是使网络比较不容易出现拥塞
    3. 快重传
        - 如果接受方收到一个失序报文 它会马上发送报告给发送方 
        - 告知它未收到报文 如果发送发收到 重复的三个确认则会立即重传确认所期待的下一个报文
        - 要求接收方收到一个失序报文段就发出重复确认(为了使发送及早知道有报文没有到达对方 可提高网络吞吐量约20%)而不需要等到自己发送数据时捎带确认
        - 快重传算法规定:
        - 发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段 而不必继续等待设置的重传计时器时间到期
    4. 快恢复
        - 快重传配合快恢复算法
        - 当发送方连续收到三个重复确认时 就执行乘法减小算法 把ssthresh门限减半(为预防网络发生阻塞)
        - 但是接下来并不执行慢开始算法 考虑到如果网络发生拥塞的话 就不会收到好几个重复的确认所以发送方现在认为网络可能没有出现拥塞 此时不执行慢开始算法
        - 将cwnd设置为ssthresh减半后的值 然后执行拥塞避免算法 使得cwnd缓慢增大
    - PS:在采用快恢复算法时 慢开始算法只在TCP连接建立时 和网络出现超时时才使用
    > 拥塞产生原因
    - 某段时间 对网络中某一资源的需求超过了该资源能提供的可用部分 
    - 即对资源的需求>可用资源
    
    > 拥塞控制分类
    1. 开环控制 设计网络时把因素考虑到
    2. 闭环控制 基于反馈环路 使用拥塞的信息来进行调整网络
    ----------
    > TCP流量控制 -- 滑动窗口
    - 作用于接受者 控制发送者的发送速度从而使接收者来得及接收 防止分组丢失 滑动窗口协议实现 构成TCP可靠性一部分
    - 接收方返回的ACK中会包含自己的接收窗口大小 并利用大小控制发送方的数据发送

    > 滑动窗口机制/连续ARQ协议
    - 包括
    1. 发送窗口(SWND) 已经发送但是没有收到ACK
    2. 接受窗口(RWND) 
    3. 拥塞窗口(CWND)
    - 其中 MAX(发送窗口) = MIN(CWND,RWND)
    - 主要包含两个过程：
        1. 收到序列i-1及以下序列 期待受到i及以后的序列
        2. 确认同意对方发送一个窗口w共j个字节 其序列号为i到i+j-1
    
    > 发送窗口&可用窗口
    - 发送方来说 窗口内包括两部分 
    1. 发送窗口(已经发送了但是没有收到ACK)
    2. 可用窗口 接收端允许发送但是没有发送的部分
    
    > 滑动窗口原理
    - 在 TCP 链接中，对于发送端和接收端而言
    - TCP 需要把发送的数据放到发送缓存区, 将接收的数据放到接收缓存区。
    - 而经常会存在发送端发送过多，而接收端无法消化的情况，所以就需要流量控制，就是在通过接收缓存区的大小，控制发送端的发送。
    - 如果对方的接收缓存区满了，就不能再继续发送了。
    - 而这种流量控制的过程就需要在发送端维护一个发送窗口，在接收端维持一个接收窗口

    > 滑动窗口协议：
    - 针对发送端和接收端一种流量控制策略
    - 某些情况下 接收端处理数据能力比发送端发送数据能力低很多 或发送端数据太多会造成接收端队列塞满
    - 因此有了滑动窗口 接收端告诉发送端一次最多可以发送多少数据
    - 滑动窗口协议保证
    1. 分组无差错 有序接收
    2. 实现流量控制

    > 滑动窗口
    - 已发送未收到ACK+未发送(接收端有空间)


    - TCP头部中有一个Window Size 这个就是接收方告诉发送方 我现在可接受容量大小
    发送数据流大小必须小于我这个容量

    1. TCP协议的使用
    2. 维持发送方/接收方缓冲区 
        缓冲区是用来解决网络之间数据不可靠的问题
        例如丢包 重复包 出错 乱序
    
    - TCP协议中 发送方和接收方通过各自维护自己的缓存区 通过商定包的重传机制等一系列操作 解决不可靠问题
    - 为了增加网络吞吐量 想将数据包一起发送过去 有了滑动窗口这个概念 解决其中出现的一些问题 如丢包 超时重传 这个ACK要按顺序 保证滑动窗口顺序 用来加速数据传输 
    - TCP要保证可靠 需要对一个数据包进行ack确认表示接受端收到 有了滑动窗口 接收端可以等收到许多包后 只发一个ack包 确认之前已经收到过的多个数据包
    - 有了滑动窗口 发送端在发送完一个数据包后不用等待它的ack 在滑动窗口大小内可以继续发送其他数据包
7. TCP和UDP(传输层协议)概念 区别 应用场景 TCP三次握手四次挥手
    > TCP:面向连接 可靠 打电话 大部分情况下 点对点 面向字节流 首部开销较大|
    > UDP:面向非连接 不可靠 广播 实时性要求高 1/多对1/多 面向报文 首部开销较小
    - (TCP三次握手 建立可靠通信信道 确认双方发送接收机能正常)
    (TCP两次握手 无法确认客户端的接收能力
    > TCP三次握手：
    1. 客户端向服务端发送SYN
    2. 服务端返回SYN,ACK
    3. 客户端发送ACK    

    > TCP四次握手 可以 会降低传输效率)
    > TCP四次挥手 传输层协议断开连接的过程 确定数据全部传输完毕)
    > TCP 是面向连接的
        可靠的传输层通信协议
        可靠(有状态/可控制)
        (可靠性(有状态 可控制)
        有状态 TCP会确认发送了哪些报文/接收方收到了哪些报文保证数据包按序到达 不允许有差错/
        可控制/流量控制 如出现丢包/网络状态不佳 则会跳转自己的行为 减少发送的速度或重发
        )
        TCP提供可靠的服务，也就是说，通过TCP连接传输的数据不会丢失，没有重复，并且按顺序到达 一个TCP连接需要三次挥手才能建立起来
    > UDP（User Data Protocol，用户数据报协议）
        是与TCP相对应的协议
        它是面向非连接的协议，它不与对方建立连接，而是直接就把数据包发送过去 
        UDP适用于一次只传送少量数据、对可靠性要求不高的应用环境
    > TCP和UDP(实时性要求较高)的应用场景：
    1. UDP 对某些实时性要求比较高的情况使用UDP，比如游戏，媒体通信，实时直播，即使出现传输错误也可以容忍；
    2. TCP 其它大部分情况下，HTTP都是用TCP，因为要求传输的内容可靠，不出现丢失的情况
    > 形容TCP和UDP：
    1. TCP通信可看作打电话：
        李三(拨了个号码)：喂，是王五吗？ 王五：哎，您谁啊？ 李三：我是李三，我想给你说点事儿，你现在方便吗？ 王五：哦，我现在方便，你说吧。 甲：那我说了啊？ 乙：你说吧。 (连接建立了，接下来就是说正事了…)
    2. UDP通信可看为学校里的广播：
        播音室：喂喂喂！全体操场集合
    
    概念：
    > 序列号 seq 32位 Sequence Number
    - TCP会话的每一端都包含一个32位(bit)的序列号 该序列号用来跟踪该端发送的数据量 每一个包中都包含序列号 在接收端则通过确认号用来通知发送端数据成功接收 当某个主机开启一个TCP会话时 它的初始化序列号是随机的 
    > 确认号 ack 32位 Acknowledgement Number
    - TCP在其协议头使用大量标志位/1位布尔域控制连接状态
    > 六个状态位(置1有效)(URG/ACK/PSH/RST/SYN/FIN)
    > 三个状态位(ACK/SYN/FIN
    - SYN 用作建立连接时的同步信号 建立TCP连接时使用
    - FIN 表示后面没有数据发送 关闭TCP连接时使用
    - ACK 表示ack Acknowledge Number字段有效
        用于对收到的数据进行确认 所确认的数据由确认序列号表示
    - seq Sequence Number 发送数据包中的第一个字节的序列号 32位
    - ack Acknowledgement Number 确认序列 32位
    - RST 表示复位 用来异常的关闭连接
    > RST攻击:
        A和服务器B之间建立TCP连接
        此时C伪造一个TCP包发给B
        使B异常断开与A之间TCP连接
        如何伪装:
            源端口号+序列号
        TCP连接：
            源IP+源端口+目的IP+目的端口号 一对Socket 唯一确定一个TCP连接
    - TCP三次握手 
        - (建立可靠通信信道/确认双方发送接收机能正常/防止出现请求超时导致脏连接)
        - TCP建立连接的过程，我们称为三次握手。起初两端都处于CLOSED关闭状态
        1. 第一次握手(客户端向服务器端发送SYN) 
            (SYN=1 seq=x Client为SYN_SENT状态)
            Client将SYN置1 随机产生一个初始序列号Seq发送给Server
            客户端进入SYN_SENT状态
        2. 第二次握手(服务器端返回SYN+ACK)
            (SYN=1 ACK=1 ack=x+1 seq=y Server为SYN_RECD)
            Server收到Client的SYN报文段 由标志为SYN=1得知Client请求建立连接
            设置ACK(Ackonwledge Number)为x+1(Sequence Number+1) 
            发送SYN请求信息 SYN=k 服务器端将上述所有信息放到一个报文段
            (即SYN+ACK报文段) 一并发送给客户端 
            服务器进入SYN_RECV状态 此时操作系统为TCP连接分配TCP缓存和变量
        3. 第三次握手(客户端发送ACK)
            (seq=x+1 ACK=1 ack=y+1
            Client&Server ESTABLISHED) 
            Client收到确认后 检查ack是否为x+1 ACK是否为1
            如果正确 则将标志位ACK置为1 ack=y+1
            此时操作系统为该TCP连接分配TCP缓存和变量
            并将数据包发送给Server
            Server检查ack是否为y+1 ACK是否为1 
            如果正确则连接建立成功
            Client和Server进入EATABLISHED状态
            完成三次握手 
            Client与Server开始传输数据
    > TCP为什么不能两次握手
    1. 不能确认客户端接收能力
    2. 防止已失效的连接请求报文段突然传送到Server 产生错误
    
    > TCP可以四次握手吗
    1. 可以 但是会降低传输效率。
    
    > Server端易受到SYN攻击
    - 服务端Server资源分配是在二次握手时分配的
    - 客户端Client资源是在完成三次握手时分配的
    - Server易受到SYN洪泛攻击
    > SYN攻击概念：
        Client短时间内伪造大量不存在的IP地址 并向Server不断发送SYN包
        Server回复确认包 等待Client确认 由于源地址不存在 因此Server需要不断重发至超时
        这些伪造的SYN包将长时间占用未连接队列 导致正常的SYN请求因为队列满而被丢弃 从而引起网络拥塞甚至系统瘫痪
    > 防范SYN攻击措施
    1. 降低主机的等待时间使主机尽快的释放半连接的引用
    2. 短时间受到某IP的重复SYN则丢弃后放弃后续请求

    > 第三次握手中，如果客户端的ACK未送达服务器，会怎样？
    - Server端：
        - 由于Server没有收到ACK确认 会每隔3秒 重发之前的SYN+ACK    
        - 默认重发五次，之后自动关闭连接进入CLOSED状态）Client收到后会重新传ACK给Server。
    - Client端两种情况
    1. 在Server进行超时重发的过程中
        - Client向服务器发送数据，数据头部的ACK是为1的 服务器收到数据之后会读取 ACK number 进入 ESTABLISHED 状态
    2. 在Server进入CLOSED状态之后
        - 如果Client向服务器发送数据 服务器会以RST包应答。
    
    > 已经建立了连接 客户端出现了故障如何处理
    - 服务器每收到一次客户端的请求后重新复位一个计时器 时间通常是设置为2小时
    - 若两小时还没有收到客户端的任何数据，服务器发送一个探测报文段
    - 以后每隔75秒钟发送一次 若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障 关闭连接。

    > TCP四次挥手 
    - (传输层协议断开连接的过程 目的确定数据全部传输完毕)
    四次挥手：
    1. 第一次挥手
        (FIN=1 seq=u
        Client为FIN_WAIT_1)
        Client将FIN置为1，发送一个序列号SEQ给Server
        Client进入FIN_WAIT_1状态 表明Client已经没有数据要发送给Server了
    2. 第二次挥手
        (ACK=1,ack=u+1,seq=v
        Server为CLOSE_WAIT)
        Server收到FIN之后，发送一个ACK=1，acknowledge number=收到的序列号+1
        Server进入CLOSE_WAIT状态
        此时客户端已经没有要发送的数据了，但仍可以接受服务器发来的数据。
    3. 第三次挥手
        (FIN=1 ACK=1 seq=w ack=u+1
        Client为FIN_WAIT_2
        Server为LAST_ACK)
        Server将FIN置1，发送一个序列号给Client
        Server进入LAST_ACK状态；
    4. 第四次挥手
        (ACK=1 seq=u+1 ack=w+1
        Client为TIME_WAIT
        Server为CLOSED
        Client等待2*MSL CLOSED)
        Client收到服务器的FIN后，进入TIME_WAIT状态
        接着将ACK置1，发送一个ACKacknowledge number=序列号+1给服务器；
        服务器收到后 确认acknowledge number后，变为CLOSED状态，不再向客户端发送数据。
        客户端等待2*MSL（报文段最长寿命）时间后，也进入CLOSED状态。完成四次挥手。

    > TCP服务器最大并发连接数
        关于TCP服务器最大并发连接数有一种误解就是“因为端口号上限为65535
        所以TCP服务器理论上的可承载的最大并发连接数也是65535”
        首先需要理解一条TCP连接的组成部分：客户端IP 客户端端口 服务端IP 服务端端口
        所以对于TCP服务端进程来说，他可以同时连接的客户端数量并不受限于可用端口号，理论上一个服务器的一个端口能建立的连接数是全球的IP数*每台机器的端口数
        实际并发连接数受限于linux可打开文件数，这个数是可以配置的，可以非常大，所以实际上受限于系统性能
        通过#ulimit -n查看服务的最大文件句柄数，通过ulimit -n xxx 修改 xxx是你想要能打开的数量。也可以通过修改系统参数：
    > 为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE_WAIT状态意义是什么）？
    - 因为服务器收到客户端断开连接的请求时 可能还有一些数据没有发完，这时先回复ACK，表示接收到了断开连接的请求。等到数据发完之后再发FIN，断开服务器到客户端的数据传送。

    > 如果第二次挥手时服务器的ACK没有送达客户端，会怎样？
    - 客户端没有收到ACK确认，会重新发送FIN请求。
    
    > 客户端TIME_WAIT状态的意义是什么(确保Server收到ACK)
    1. 保证Client发送最后一个ACK报文段能到达Server
    2. 防止已失效的连接请求报文段出现在本连接中
    - 第四次挥手时，客户端发送给服务器的ACK有可能丢失，TIME_WAIT状态就是用来重发可能丢失的ACK报文
    - 如果Server没有收到ACK，就会重发FIN，
    - 如果Client在2*MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL，防止Server没有收到ACK而不断重发FIN。
    - 优化 可以通过修改系统参数优化服务器
        tcp_tw_reuse: 是否重用处于TIME_WAIT状态的TCP链接 （设为true）
        tcp_max_tw_buckets: 处于TIME_WAIT状态的SOCKET最大数目 （调大，这个参数千万不要调小了）
        tcp_fin_timeout: 处于FIN_WAIT_2的时间 （调小）
    
    > TIME_WAIT状态还需要等2MSL后才能返回到CLOSED状态会有什么问题
        通信双方建立TCP连接后，主动关闭连接的一方就会进入TIME_WAIT状态
        TIME_WAIT状态维持时间是两个MSL时间长度，也就是在1-4分钟
        Windows操作系统就是4分钟
        进入TIME_WAIT状态的一般情况下是客户端
        一个TIME_WAIT状态的连接就占用了一个本地端口
        一台机器上端口号数量的上限是65536个
        如果在同一台机器上进行压力测试模拟上万的客户请求
        并且循环与服务端进行短连接通信
        那么这台机器将产生4000个左右的TIME_WAIT Socket
        后续的短连接就会产生address already in use : connect的异常
        如果使用Nginx作为方向代理也需要考虑TIME_WAIT状态
        发现系统存在大量TIME_WAIT状态的连接，通过调整内核参数解决。
    
    > MSL(Maximum Segment Lifetime)
        指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。
    > 为什么连接是三次握手 关闭却是四次握手
    1. 连接时
        Server收到Client端的SYN请求报文后 可以直接发送SYN+ACK报文 ACK用来应答 SYN用来同步
    2. 关闭时
        Server端收到FIN报文时 很可能不会立即关闭SOCKET 所以只能先回复一个ACK报文 告诉Client端 你发的FIN报文我收到了只有Server端所有报文都发送完毕 Server才能发送FIN报文 因此不能一起发送 故需要四次握手
    > 关于TCP/IP与HTTP协议关系    
        我们在传输数据时 可以只使用(传输层)TCP/IP协议 但如果没有应用层 便无法是被数据内容 如想要使传输的数据有意义 则必须使用应用层协议
8. http1.0/http1.1(目前使用最为广泛的HTTP协议)/http2.0
    - http1.0&http1.1&http2
    (
    1. 连接方面
    2. 资源请求方面
    3. 缓存方面
    4. Host头处理
    5. 新增方法
    6. 新增错误管理状态码
    )
    1. 连接方面 HTTP1.1默认持久连接 HTTP1.0默认非持久连接
        - http1.1 默认使用持久连接 
        - http1.0 默认使用非持久连接 
        > http1.1 通过使用持久连接来使多个http请求复用同一个 TCP连接 避免使用非持久连接时每次需要建立连接的时延。
    2. 资源请求方面 HTTP1.1支持断点续传功能
        - http1.0 中 存在一些浪费带宽的现象 如客户端只是需要某个对象的一部分 服务器却将整个对象送过来了，不支持断点续传功能
        - http1.1 则在请求头引入了 range 头域 它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
    3. 缓存方面 HTTP1.1增加Etag If-None-Match
        - http1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准
        - http1.1 则引入了更多的缓存控制策略例如 Etag、If-Unmodified-Since、If-Match、If-None-Match 等更多可供选择的缓存头来控制缓存策略。
    4. Host头处理 HTTP1.1新增host字段指定服务器域名
        - http1.1 中新增 host 字段用来指定服务器的域名
        - http1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，请求消息中的 URL 并没有传递主机名（hostname）。
        > 随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个IP地址。因此有了 host 字段，就可以将请求发往同一台服务器上的不同网站。
    5. 新增方法/错误管理状态码 
        HTTP1.1新增方法 错误管理状态码 PUT、HEAD、OPTIONS/
        在HTTP1.1中新增了24个错误状态响应码 
        如409(Conflict)表示请求的资源与资源的当前状态发生冲突
        401(Gone)表示服务器上的某个资源被永久性的删除
    - http1.x&http2.0
        1. 新的二进制格式
        2. 多路复用
        3. header压缩
        4. 服务端推送
    1. 新的二进制格式(Binary Format)
        - (HTTP1.x解析基于文本/HTTP2.0解析采用二进制格式)
        - HTTP1.x的解析基于文本 基于文本协议的格式解析存在天然缺陷 文本表现形式有多样性 要做到健壮性考虑到的场景必然很多
        - 二进制则不同 只认0和1的组合 HTTP2.0协议解析决定采用二进制格式 实现方便且健壮
    2. 多路复用(MultiPlexing) 
        - 连接共享 每一个request都是用作连接共享机制 一个request对应一个id 这样一个连接上可以有多个request 
        - 每个连接的request可以随机混杂在一起 接收方可以根据request的id将request再归属到各自不同的服务端请求
    3. header压缩 
        - HTTP1.x的header带有大量信息 每次都要重复发送 HTTP2.0使用encoder来减少需要传输的header大小 通讯双方各自cache一份header fields表 既避免了重复header的传输 又减小了需要传输的大小
    4. 服务端推送
        同SPDY一样 HTTP2.0也具有Server push功能
    - HTTP2.0升级改造
        1. HTTP2.0其实可以支持非HTTPS 但现在主流浏览器像chrome firefox 表示还是只支持基于TLS部署的HTTP2.0协议 所以要想升级到HTTP2.0还是先升级HTTS比较好
        2. 基于HTTPS 升级HTTP2.0相对简单 如果使用NGINX 只要在配置文件中启动相关协议即可
        3. HTTP1.0完全兼容 HTTP1.X语义 对于不支持HTTP2.0浏览器 NGINX会自动向下兼容   
    - http2.0多路复用和HTTP1.x中长连接复用区别
        1. HTTP1.* 一次请求-响应 建立一个连接 用完关闭 每一个请求都要建立一个连接
        2. HTTP/1.1 Pipeling解决方式
            线头阻塞
            若干个请求排队串行化单线程处理 
            后面的请求等待前面请求的返回才能获取执行机会 一旦有某请求超时 后续请求只能被阻塞 毫无办法 
            也就是人们常说的线头阻塞
        3. TTP/2多个请求可同时在一个连接上并行执行
            某个请求任务耗时严重 不会影响到其他连接的正常执行
    - HTTP2.0多路复用的好处
        - (让所有数据流共用同一个连接 可更有效地使用TCP连接 让高带宽能真正服务于HTTP性能提升)
        - (HTTP性能优化不在于高带宽 在于低延迟)
        HTTP性能优化不在于高带宽 在于低延迟 
        TCP连接会随着时间进行自我调节 起初会限制连接的最大速度 如果数据成功传输 会随着时间的推移提高传输的速度
        这种被称为TCP慢启动 由于此 让原本旧具有突发性和短时性的HTTP连接变的十分低效
        HTTP/2通过让所有数据流共用同一个连接 可以更有效地使用TCP连接 让高带宽能真正服务于HTTP性能提升
    
    > keep-aliveHTTP1.x和多路复用HTTP2区别
    并发情况下 HTTP2有多路复用机制 无论多少个HTTP请求
    都只暂用一个TCP 不会有请求阻塞
    HTTP2基于流进行数据请求 几百个请求都可以基于一个TCP连接传递 然后通过流id进行拼接返回到每个请求上 不存在线头阻塞 且只用到一个TCP 对服务器的并发量提高了6倍
    HTTP2还有头部压缩 对状态行和头信息进行哈夫曼编码压缩
        静态字典动态字典相关技术处理节省头信息优化传输浪费流量
    HTTP1.1同域请求限制6个TCP连接建立 但是HTTP1.1每个TCP都是线头阻塞的

    > HTTP 如何实现长连接？在什么时候会超时？
    通过在头部（请求和响应头）设置 Connection: keep-alive，HTTP1.0协议支持，但是默认关闭，从HTTP1.1协议以后，连接默认都是长连接
        。。。
    实际上 HTTP 没有长短链接，只有 TCP 有，TCP 长连接可以复用一个 TCP 链接来发起多次 HTTP 请求，这样可以减少资源消耗，比如一次请求 HTML，可能还需要请求后续的 JS/CSS/图片等
    
    > HTTP的options方法作用
    1.检测服务器所支持的请求方法
        (比如'/user'路由支持那些方法 get post delete)
    2.CORS中的预检请求(检测某个接口是否支持跨域)
9. HTTP
    - HTTP发展史
        1. HTTP/0.9 单行协议
            HTTP于1990问世 那时HTTP十分简单 
            只支持GET方法 没有首部 只能获取纯文本
        2. HTTP/1.0 搭建协议的框架
            1996 HTTP正式被作为标准公布
            1.0版本增加了
                首部 
                状态码 
                权限 
                缓存 
                长连接(默认短连接)
            搭建了协议的基本框架
        3. HTTP/1.1 进一步完善
            1997 改进
                默认长连接
                支持断点续传
                Cache-Control
                ETag等缓存相关扩展
                强制客户端提供Host首部
                管线化
                新增错误码 请求方式
        - 目前存在问题
        - (线头阻塞/多个TCP连接/ - 多路复用 header头部压缩
        头部冗余采用文本格式 - 二进制格式/
        客户端需主动发起请求 - 服务器端推送)
        1. 线头阻塞
            TCP连接上只能发送一个请求 前面的请求未完成前 后续请求都在排队等待
        2. 多个TCP连接
            虽然HTTP/1.1管线化可以支持请求并发 但是浏览器很难实现 chrome/firefox等都禁用管道化 HTTP/1.1请求并发依赖于多个TCP连接 建立TCP连接成本高 存在慢启动问题
        3. 头部冗余,采用文本格式
            HTTP/1.x版本采用文本格式
            首部未压缩
            每一个请求都会带上cookie
            user-agent等完全相同的首部
        4. 客户端需要主动请求
        > HTTP2(二进制分帧层)
            性能提升核心 二进制分帧层
            HTTP2是二进制协议 采用二进制格式传输数据
            而不是1.x的文本格式
            1.1响应是文本格式
            2.0把响应划分成两个帧
                帧的类型
                Headers首部
                Data消息负载
            一条HTTP响应 划分了两个帧传输 并且采用二进制编码
        - 三个概念
            1. 流/Stream 
                已建立的TCP连接上的双向字节流 
                可以承载一个或多个消息
            2. 消息/Message 
                一个完整的HTTP请求/响应 
                由一个或多个帧组成 
                特定消息的帧在同一个流上发送
                意味着一个HTTP请求/响应
                只能在一个流上发送
            3. 帧/Frame
                一个TCP连接上可以有任意数量的流
        - HTTP2
            (二进制分帧层)
            (多路复用/头部压缩/服务器端推送)
            1. 多路复用 (解决了HTTP/1.1线头阻塞/多个TCP连接问题)
            HTTP2让所有通信都在一个TCP连接上完成 真正实现了请求的并发
            具体实现
                基于流进行传输
                HTTP2建立一个TCP连接 
                一个连接上面可以有任意多个流 
                消息分割成一个/多个帧在流里面传输 
                帧传输过去后 
                再进行重组 
                形成一个完整的请求/响应
                使得所有的请求/响应都无法阻塞
            2. 头部压缩(静态字典 哈夫曼编码/动态字典)
                HTTP2采用HPACK压缩格式压缩首部
                头部压缩需要再浏览器和服务器端之间
                    维护一份相同的静态字典
                    维护一份相同的动态字典
                    通过静态Huffman编码对传输的首部字段进行编码
            3. 服务器端推送
                使得服务器可以预测客户端需要资源 主动推送到客户端
                实现原理：
                    客户端发出页面请求时 
                    服务器端能分析这个页面所依赖的其他资源 
                    主动推送到客户端缓存 
                    客户端收到原始页面请求时 
                    它需要的资源已经位于缓存        
10. HTTP(80端口)和HTTPS(443端口)的区别 HTTPS有哪些新特性 SSL协议解决了什么，其依靠的算法有哪些
    - 区别:
        HTTPS = HTTP + SSL/TLS(Secure Socket Layer安全套接层)
                TLS(Transport Layer Security 继任者传输层安全)
                    TLS和SSL在传输层对网络连接进行加密
        HTTP 无CA证书 运行在TCP上 内容明文传输 默认80端口 |
        HTTPS(SSL 身份验证|加密|完整) 防止MIMT攻击 有CA证书 运行在SSL/TLS之上 SSL/TLS运行在TCP之上 内容加密传输 默认443端口 相对于 HTTP 性能上差点 多了 SSL/TLS 的几次握手和加密解密的运算处理 加密解密的运算处理已经可以通过特有的硬件来加速处理。
    - HTTP(Hypertext transfer protocol)超文本传输协议，规定了超文本传输(文本 图片 视频)所要遵守的规则。
    - 优点(灵活/可靠/请求-应答/无状态)
        1. 灵活可扩展，除了规定空格分隔单词，换行分隔字段以外，其他都没有限制，不仅仅可以传输文本，还可以传输图片、视频等任意资源
        2. 可靠传输，基于 TCP/IP 所以继承了这一特性
        3. 请求-应答，有来有回
        4. 无状态，每次 HTTP 请求都是独立的，无关的、默认不需要保存上下文信息
    - 缺点(明文传输不安全/复用一个TCP连接 发生对头拥塞/无状态 长连接中需保存大量上下文)
        1. 明文传输不安全
        2. 复用一个 TCP 链接，会发生对头拥塞
        3. 无状态在长连接场景中，需要保存大量上下文，以避免传输大量重复的信息
    - HTTPS新特性:(TLS/SSL内容加密|CA证书验明身份防止MIMT攻击|MD5 SHA-1等散列值防止信息篡改)
        1. TLS/SSL内容加密
        2. 数字证书(CA)验明身份：防范中间人MIMT攻击
        3. MD5,SHA-1等散列值方法防止信息篡改
    - HTTPS安全性(服务器身份验证|数据加密|完整)
        1. 服务器身份验证，通过服务器身份验证，用户可以明确当前它正在与对应的服务器进行通信
        2. 数据机密性，其他方无法理解发送的数据内容，因为提交的数据是加密的
        3. 数据完整性，传输会携带Message Authentication(MAC)用作验证，因此传输的数据不会被另一方更改
    - HTTPS优点缺点
        - 优点：(安全)
            1. 最大限度地提高 Web 上数据和事务的安全性；
            2. 加密用户敏感或者机密信息；
            3. 提高搜索引擎中的排名
            4. 避免在浏览器中出现“不安全”的提示；
            5. 提升用户对网站的信赖。
        - 缺点：
            1. HTTPS 协议在握手阶段耗时相对较大，会影响页面整体加载速度；
            2. 在浏览器和服务器上会更多的 CPU 周期来加密/解密数据；
            3. SSL 证书一般都需要支付一定费用来获取，并且费用往往不低；
            4. 并不是绝对意义上的安全，在网站遭受攻击，服务器被劫持时，HTTPS 基本起不到任何安全防护作用。
    - SSL(信息窃听/篡改/劫持 => 加密/完整性校验/身份校验 =>机密性/可靠性/完整性)
    原有风险 现有优势
    1. 信息窃听  信息加密
    2. 信息篡改  完整性校验
    3. 信息劫持  身份验证
    - SSL协议提供的安全通道有以下三个特性：
    1. 机密性：SSL协议使用密钥加密通信数据。
    2. 可靠性：服务器和客户都会被认证，客户的认证是可选的。
    3. 完整性：SSL协议会对传送的数据进行完整性检查。
    - 主要包含两部分
        1. Record记录协议 使用对称加密转发来解决通讯消息加密的部分
        2. Handshake握手协议 为了完成对称加密，需要通过握手协议来传递密匙  
    - 加密算法分为两大类：
        1. 对称加密算法
            数据加解密使用同一份密钥，加解密速度快，效率高，缺点是密钥的管理难度大，一旦密钥传输泄露，那就没啥用处了。
        2. 非对称加密算法
            数据加解密使用公钥和私钥，公钥用于传输，私钥自己保存，安全性较高，但加解密速度偏慢。
    - 公钥和私钥的概念
        1. 私钥（放在服务器上，用于公钥加密过的数据），不会放在互联网上传输；
        2. 公钥（放在互联网上，所有人都能拿到的一串加密的字符串，这个加密的字符串是来加密我们的字符信息的。当加密的数据传到服务器上，只有服务器通过私钥解密，才能把公钥加密的数据拿出来）
    - SSL握手三个目的：
        (客户端服务端确认算法/确认算法所使用加密密匙/选择对客户端进行认证)
        1. 客户端与服务端需要就一组用于保护的算法达成一致
        2. 它们需要确立一组由那些算法所使用的加密密匙
        3. 握手还可以选择对客户端进行认证
    - SSL握手过程
        1. 客户端 --支持算法列表 一个用作产生密匙的随机数-->服务器
        2. 服务器 --算法列表中选择一种加密算法+服务器公钥+一个用于产生密匙的随机数 -->客户端
        3. 客户端 --对服务器证书验证 过程类似数字签名+抽取服务器公匙+产生一个pre_master_secret随机密码串+服务端公钥加密 -->服务端
        4. 客户端&服务端 根据pre_master_secret&随机数 独立计算出加密和MAC密匙
        5. 客户端 -- 所有握手信息的MAC -->服务器
        6. 服务器 -- 所有握手信息的MAC -->客户端)
        (SSL握手通过交换三个随机数 计算出主会话密匙 由于安全性 会继续扩展出更多临时密匙 保证通讯过程绝对安全)   

        (对方公钥加密 自己私钥解密)
        1. 客户端和服务器建立连接后 各自生成私钥和公钥
        2. 服务器返给客户端一个公钥
        3. 客户端拿着公钥把要传输的内容进行加密 连同自己的公钥一起返给服务器
        4. 服务器用自己的私钥解密密文然后把响应的数据用客户端公钥加密返回给客户端 
        5. 客户端用自己的私钥解密密文 完成数据展
11. keep-alive标签
    - HTTP1.0中(默认使用Connection:close)
        - 早期在HTTP1.0协议中附加keep-alive字段 connection:keep-alive
        - 客户端发送HTTP包含一个keep-alive端 服务器端识别并返回一个keep-alive这样一个保持的连接就建立了
    - HTTP1.1中(默认使用Connection:keep-alive)
        - 所有连接都默认被保持
        - 这时客户端发送一个connection:close关闭连接
    - HTTP中的keep-alive和TCP中的keep-alive
        - HTTP中
            相当于保存了一个连接池
            使用完之后不会立即销毁而是放在池子中
        - TCP中
            保活机制 防止对面服务器挂掉
            浪费这个连接 如果挂掉之后会返回rst
    - 如果一个连接是不会断开 多个请求如何区分 即浏览器如何知道当前请求已经完成
        HTTP在header中添加一个Content-Length字段

    > 在交互过程中如果数据传送完了，还不想断开连接怎么办，怎么维持？
    - 在 HTTP 中响应体的 Connection 字段指定为 keep-alive
12. WebSocket
    - WebSocket H5一种新协议 实现浏览器和服务器全双工通信 一开始握手需借助HTTP请求完成 请求成功 单独建立一条TCP通信信道进行数据传输 被用作即时通讯 代替轮询
    - WebSocket协议本质上是一个基于TCP的协议
    - WebSocket 是 HTML5 开始提供的一种在单个 TCP 连接上进行全双工通讯的协议。
    -  使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。
    - 在 WebSocket API 中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。
    - WebSocket 是长轮询。
    > 长轮询和短轮询
    1. 具体比如在一个电商场景，商品的库存可能会变化，所以需要及时反映给用户，所以客户端会不停的发请求，然后服务器端会不停的去查变化，不管变不变，都返回，这个是短轮询。
    2. 而长轮询则表现为如果没有变，就不返回，而是等待变或者超时（一般是十几秒）才返回，如果没有返回，客户端也不需要一直发请求，所以减少了双方的压力。
12. WebSocket与Ajax的区别
    - 本质不同
        Ajax（Asynchronous Javascript And XML） 即异步 JavaScript 和 XML。是一种创建交互式网页的应用的网页开发技术 websocket 是 HTML5 的一种新协议，实现了浏览器和服务器的实时通信
    - 生命周期不同：
        websocket 是长连接，会话一直保持
        ajax 发送接收之后就会断开
    - 适用范围：
        websocket 用于前后端实时交互数据    
        ajax 非实时
    - 发起人：
        AJAX 客户端发起 
        WebSocket 服务器端和客户端相互推送    
12. WebSocket Socket(套接字) HTTP HTTPS
    > WebSocket
    - 通常应用层协议都是完全基于网络层协议TCP/UDP实现 例如HTTP SMTP POP3 
    - WebSocket同时基于HTTP与TCP实现 先用带有 Upgrade:Websocket头Header的特殊HTTP request来实现与服务端握手HandShake;握手成功后，协议升级成Websocket，进行长连接通讯；

    > Socket 
    - 长连接 客户端和服务器端互相连接 一旦建立不会主动挂掉 一个Socket由一个IP地址和一个端口号唯一确定)
    - 一个Socket 源IP+源端口+目的IP+目的端口)
    1. 网络上的两个程序通过一个双向的通讯连接实现数据的交换，这个双向链路的一端称为一个Socket。
        - Socket通常用来实现客户方和服务方的连接。
        - Socket是TCP/IP协议的一个十分流行的编程界面，
    2. Socket所支持的协议种类也不光TCP/IP、UDP，
        因此两者之间是没有必然联系的。
        在Java环境下，Socket编程主要是指基于TCP/IP协议的网络编程。
    3. Socket连接就是所谓的长连接，
        客户端和服务器需要互相连接，
        理论上客户端和服务器端一旦建立起连接将不会主动断掉的，但是有时候网络波动还是有可能的
    4. Socket偏向于底层

    > Socket和WebSocket关系
    - Socket是传输控制层协议 WebSocket是应用层协议
    - Socket其实不是一个协议 是为了方便使用TCP/UDP而抽象出来的一层 是位于应用层和传输控制层之间的一组接口     

    > Socket和http的区别和应用场景
    1. Socket连接就是所谓的长连接，理论上客户端和服务器端一旦建立起连接将不会主动断掉；
    2. Socket适用场景：网络游戏，银行持续交互，直播，在线视屏等。
    3. http连接就是所谓的短连接，即客户端向服务器端发送一次请求，服务器端响应后连接即会断开等待下次连接
    4. http适用场景：公司OA服务，互联网服务，电商，办公，网站等等等等 

    > HTTP(应用层)
    - Http协议是对客户端和服务器端之间数据之间实现可靠性的传输文字/图片/音频/视频等超文本数据的规范 格式简称为“超文本传输协议”
    - 定义了在与服务器交互的不同方式 最常用的方法有四种
    - 分别是
        1. GET 
        2. POST 
        3. PUT 
        4. DELETE 
    
    - URL全称为资源描述符 一个URL地址对应着网络上一个资源
    - HTTP中的GET POST PUT DELETE  对应着这个资源的查询 修改 增添 删除 四个操作

    > HTTP请求由三个部分构成
    1. 状态行
    2. 请求头(Request Header)
    3. 请求正文
    > HTTP响应由三个部分构成
    1. 状态行
    2. 响应头(Response Header)
    3. 响应正文
    
    > 为什么不使用HTTP长连接来实现即时通讯
    - 事实上，在Websocket之前就是使用HTTP长连接这种方式，如Comet。但是它有如下弊端：
    - HTTP 1.1 规范中规定，客户端不应该与服务器端建立超过两个的 HTTP 连接， 新的连接会被阻塞。
    - 对于服务端来说，每个长连接都占有一个用户线程，在NIO或者异步编程之前，服务端开销太大。

    > 为什么不直接使用Socket编程，基于TCP直接保持长连接，实现即时通讯？
    - Socket编程针对C/S模式的，而浏览器是B/S模式，浏览器没法发起Socket请求，正因如此， W3C最后还是给出了浏览器的Socket----Websocket。
    
    > HTTPS
    - HTTP和HTTPS区别
        1. https需要拿到CA证书，需要钱
        2. 端口不一样，http是80，https443
        3. http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。
        4. http和https使用的是完全不同的连接方式
        - （http的连接很简单，是无状态的；HTTPS 协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全）
    > HTTPS开发主要目的(加密 身份认证 完整性)
    - 提供对网站服务器的身份认证
    - 保护交换数据的隐私与完整性
    其实就是
    - HTTP+加密+身份认证+完整性保护
    - 为兼顾安全与效率 HTTPS同时使用对称加密和非对称加密
    - 要传输的数据使用了对称加密 对称加密的过程需要客户端一个密钥 为确保能把该安全传输到服务器端 讲该秘钥进行非对称加密
    > 总结：数据进行对称加密 对称加密使用的秘钥进行了非对称加密

    (对方公钥加密 自己私钥解密)
    1. 客户端和服务器建立连接后 各自生成私钥和公钥
    2. 服务器返给客户端一个公钥
    3. 客户端拿着公钥把要传输的内容进行加密 连同自己的公钥一起返给服务器
    4. 服务器用自己的私钥解密密文然后把响应的数据用客户端公钥加密返回给客户端 
    5. 客户端用自己的私钥解密密文 完成数据展现
    (数据进行对称加密 对称加密使用的密匙进行非对称加密)
    > HTTPS原理
    - HTTPS在内容传输的加密上使用的是对称加密 非对称加密只作用于证书验证阶段
    > HTTPS整体过程
    1. 证书验证
        1.浏览器发起HTTPS请求
        2.服务器返回HTTPS证书
        3.客户端验证证书是否合法不合法则提示告警
    2. 数据传输阶段
        1.当证书验证合法后 在本地生成随机数
        2.通过公式加密随机数 并把加密后的随机数传输到服务端
        3.服务端通过私钥对随机数进行解密
        4.服务端通过客户端传入的随机数构造对称加密算法 对返回结果内容进行加密后传输
    
    > 为什么数据传输用对称加密 
    1. 非对称加密加解密效率非常低 HTTP应用场景中通常端与端之间存在大量交互 非对称加密的效率无法接收
    2. HTTPS场景中只有服务器端保存了私钥 一对公私钥只能实现单向加解密 所以HTTPS中内容传输加密采取对称加密而不是非对称加密
    
    > 为什么CA认证机构颁发证书
    - HTTP协议被认为不安全是因为传输过程容易被监听者勾线监听 伪造服务器
    - HTTPS协议主要解决网络传输安全问题 由于缺少对证书的验证 所以客户端虽然发起的是HTTPS请求 但客户端完全不知道自己的网络已被拦截 传输内容被中间人全部窃取
        
    > 浏览器如何保证CA证书合法性
    1. 证书包含信息
    2. 证书合法性依据
    3. 浏览器如何验证证书合法性
        - 浏览器发起HTTPS请求时 服务器会返回网站的SSL证书 浏览器需要对证书做以下验证
        1. 验证域名有效期等信息是否正确 证书上都包含这些信息 比较容易完成验证
        2. 判断证书来源是否合法
        3. 判断证书是否被篡改 需要与CA服务器进行校验
        4. 判断证书是否已吊销
        - 以上任意一步都满足情况下 浏览器才认为证书合法

    > 本地随机数被窃取怎么办
    - 证书验证是采用非对称加密实现 传输过程是采用对称加密
    - 其中对称加密算法中重要的随机数是由本地生成并且存储于本地的
    - HTTPS并不包含对随机数的安全保证 HTTPS保证的只是传输过程安全 随机数存储于本地 本地安全属于另一安全范畴 应对措施有安装杀毒软件 反木马 浏览器升级修复漏洞等

    > HTTPS原理
    - HTTP请求都是明文传输 此处的明文就是指没有经过加密的信息 Netscape公司制定HTTPS协议 HTTPS可以将传输的数据进行加密
    - HTTPS协议=HTTP协议+SSL/TLS协议 需要用SSL/TLS对数据进行加密和解密
    > SSL Secure Socket Layer 安全套接层协议
    > TSL Tranport Layer Security 安全传输层协议 它建立在SSL协议规范之上 是SSL的后续版本
    > TSL和SSL各自所支持的加密算法不同
    - 但在理解HTTPS过程中 可以把它们看作同一种协议
    
    > HTTPS开发主要目的
    - 提供对网站服务器的身份验证保护交换数据的隐私和完整性
    - HTTP+加密+身份认证+完整性保护
    
    > 为了兼顾安全与效率 HTTPS同时使用对称加密和非对称加密
    1. 要传输的数据使用了对称加密 
        - 对称加密的过程需要客户端一个秘钥
    2. 为了确保能把该密钥安全地传输到服务器端
        将该秘钥进行了非对称加密
    - PS：数据进行对称加密 
        对称加密使用的秘钥进行了非对称加密
    
    > 客户端和服务器建立连接后 
    1. 各自生成私钥和公钥
    2. 服务器返回客户端一个公钥
    3. 客户端拿着公钥把要传输地内容进行加密
    4. 服务器端用自己的私钥解密密文 把响应的数据用客户端公钥加密 再返回给客户端 
    5. 客户端用自己的私钥解密密文 完成数据展现
    
    > HTTPS工作原理
    1. 首先HTTP请求服务端生成证书，客户端对证书的有效期、合法性、域名是否与请求的域名一致、证书的公钥（RSA加密）等进行校验；
    2. 客户端如果校验通过后，就根据证书的公钥的有效， 生成随机数，随机数使用公钥进行加密（RSA加密）；
    3. 消息体产生的后，对它的摘要进行MD5（或者SHA1）算法加密，此时就得到了RSA签名；
    4. 发送给服务端，此时只有服务端（RSA私钥）能解密。
    5. 解密得到的随机数，再用AES加密，作为密钥（此时的密钥只有客户端和服务端知道）
13. TCP HTTP Socket Socket连接池
    > 池：
    - 一种资源的集合
    > Socket：
    - 维护着一定数量Socket长连接的集合
    - 它能自动检测Socket长连接的有效性 剔除无效的连接 补充连接池的长连接的数量
    - 代码层面上其实是认为实现这种功能的类 一般一个连接池包含下面几个属性
    1. 空闲可使用的长连接队列
    2. 正在运行的通信的长连接队列
    3. 等待去获取一个空闲长连接的请求的队列
    4. 无效长连接的剔除功能
    5. 长连接资源池的数量配置
    6. 长连接资源的新建功能
    > 场景： 
    - 一个请求过来，首先去资源池要求获取一个长连接资源，如果空闲队列里面有长连接，就获取到这个长连接Socket,并把这个Socket移到正在运行的长连接队列。
    - 如果空闲队列里面没有，且正在运行的队列长度小于配置的连接池资源的数量，就新建一个长连接到正在运行的队列去
    - 如果正在运行的不下于配置的资源池长度，则这个请求进入到等待队列去。
    - 当一个正在运行的Socket完成了请求，就从正在运行的队列移到空闲的队列，并触发等待请求队列去获取空闲资源，如果有等待的情况。
14. Cookie Session Token JWT(基于token实现)
    - (HTTP无状态协议 浏览器不会保存任何会话信息 服务器端无法确定访问者
    - Cookie/Session/Token/JWT 用于客户端和服务器端进行会话验证的凭证 )
    
    > Cookie 存储在客户端 只能存储字符串数据 可设置任意时间有效 cookie.setMaxAge() 不超过4k 不可跨域 CSRF
    
    > Session(基于Cookie实现) 存储在服务器端 SessionId存储在Cookie中 任意类型数据 失效时间短 存储容量大 占用服务端资源 服务器集群状态下 无法轻易做到资源共享)
    - Session 一种记录服务器和客户端会话状态的机制，使服务端有状态化，可以记录会话信息。
    
    > Session认证过程 客户端请求 服务端创建返回 客户端收到存储 再次访问带上 服务端从Cookie中找SessionId找对应Session
    1. 客户端第一次发送请求到服务端，服务端根据信息创建对应的Session，并在响应头返回SessionID(Set-Cookie)
    2. 客户端接收到服务器端返回的SessionID后，会将此信息存储在Cookie上，同时会记录这个SessionID属于哪个域名
    3. 当客户端再次访问服务器端时，请求会自动判断该域名下是否存在Cookie信息，如果有则发给服务器端，服务器端会从Cookie中拿到SessionID，再根据SessionID找到对应的Session，如果有对应的Session则通过，继续执行请求，否则就中断

    > Token 访问API所需资源凭证 不需存储服务端 服务端只需根据客户端传来的Token进行合法验证 需要对服务器端数据库进行查询
    - Token 令牌，访问资源接口（API）时所需要的资源凭证 使服务端无状态化，不会存储会话信息。)
    - PS：这种方式的特点就是客户端的Token自己保留大量信息 服务器没有存储这些信息

    > JWT header(Base64URL).payload(Base64URL).signature(header中alg指定算法加密
    - JWT:存放在cookie/localStorage中 服务端验证客户端发来的token信息要进行数据的查询操作；
    - JWT验证客户端发来的token信息不用数据库查询 在服务端使用密钥校验就可以
    
    - 不需要查询数据库 服务器端密钥进行解密 signature验证
    - 服务器端获取header中的JWT 用Base64URL算法解码各部分
    - 服务端使用同样的密钥和算法生成signature 如与JWT中的signature相同 则JWT合法

    > 基于Token实现 流程 客户端收到后会存储在cookie/loacalStorage
    1. 客户端发送用户信息给服务端请求登录
    2. 服务端验证用户信息，验证通过后签发一个 Token 返回给客户端，客户端收到后会存储在 Cookie 或 localStorage 中
    3. 客户端继续第二次业务请求，请求头的 Authorization 字段携带这个 Token或者直接放在 Cookie(但是这样就不能跨域了)
    4. 服务端根据 headers 中的 Token 进行验证，验证通过后返回业务请求的数据

    > Token和JWT区别：
    1. Token需要查数据库验证Token是否有效 令牌 是访问资源的凭证 
    2. JWT
        > JWT JSON Web Token缩写 将用户信息加密到Token中 服务器不保存任何内部信息 服务器通过使用保存的密匙验证Token的正确性 只要正确即通过验证
        - 包含三部分
        1. Header 头部
        2. Payload 负载
        3. Signature 签名
        - 由三部分生成token 三部分之间用.作分割
        - 不用查数据库/少查询数据库 直接在服务器端进行校验 并且不用查库
        - 因为用户的信息及加密信息在第二部分payload负载和第三部分signature签证中已经生成 
        - 只要在服务端进行校验就行 校验也是JWT自己实现的

    > Cookie Session存在意义
    1. (HTTP无状态协议 浏览器不会保留任何会话信息 服务端无法确定访问者 用于客户端和服务端进行会话验证的凭证)
    2. (Cookie里可以存储JSON格式的数据 JSON格式数据其实就是符合key-value键值对的字符串格式数据)
    3. 浏览器和服务端会进行一个会话跟踪，在进行一些特殊用户权限才有的操作时，将用户状态用Cookie或Session保存起来 用于客户端和服务器端进行会话验证的凭证 )

    > Cookie/Session对比
    > 共同点
    - 保存用户状态 客户端和服务端进行会话验证的凭证
    > 不同点
    1. Cookie 存储在客户端 只能存储字符串数据 cookie.setMaxAge()可以设置任意时间有效 不超过4k cookie不可跨域 会受到CSRF攻击 受到跨域限制
    2. Session(基于Cookie实现) 存储在服务器端 占用资源 SessionId存储在Cookie中 任意类型数据 失效时间短 存储容量大 服务器集群情况下 无法轻易做到共享 需要借助缓存 由于是借助cookie实现的 可能会受到CSRF攻击 基于cookie实现 不可跨域
    
    > Session/Token对比
    1. Session 一种记录服务器和客户端会话状态的机制 占用服务端资源 使服务器端有状态化 可以存储会话信息 服务器集群需要用到缓存做资源共享 会受到CSRF攻击 基于cookie实现有跨域问题 多点登录
    2. Token 令牌 访问API所需资源凭证 不占用服务端资源 使服务器端无状态化 不会存储会话信息 不会受到CSRF攻击 不受同源策略限制 单点登录)


    > Token/JWT
    1. Token: 访问API所需资源凭证 令牌 不需存储在服务器端 服务端验证客户端发来的token信息 要进行数据的查询操作 完全由应用管理 避开同源策略 避免受到CSRF攻击 
    - 服务器端验证方法：查询服务器端数据库
    2. JWT验证客户端发来的token信息 服务端使用密钥校验 不用数据库的查询 存放在cookie/localStorage中 存放在localStorage中 完全由应用管理 完全避开同源策略 避免受到CSRF攻击
    - 服务器端验证方法：
        - 服务器端获取header中的JWT 用Base64URL算法解码各部分 服务端使用同样的密钥和算法生成signature 如与JWT中的signature相同 则JWT合法)
    

    > Cookie
    - cookie不可跨域 每个cookie都会绑定单一的域名 无法在别的域名下获取使用 一级域名和二级域名之间是允许共享使用的
    > cookie跨域问题产生
    - 一个cookie从一个服务器产生 在另一个服务器需要用到 由于浏览器安全策略 cookie只能在同一域名产生和使用
    
    > cookie组成
    1. Name Value name=value String 键值对,字符串类型，用于设置Cookie 的名称和值
    2. Expires 符合 HTTP-date 规范的时间戳 指定Cookie 的生存期，用于设置Cookie的过期时间
    3. max-age non-zero-digit 在 cookie 失效之前需要经过的秒数,与expires功能相似
    4. Domain 
        域名String 指定Cookie 所属的域名，默认为当前域名
        指cookie的域名 当访问localhost的接口时会自动携带cookie
    5. Path URL 路径 指定 cookie 在哪个路径（路由）下生效，默认是 '/'
    Size
    HTTP

    > cookie创建方式
    1. 客户端通过js设置，举例，用一个js-cookies库 已封装好document.cookie方法
    2. 服务器端通过在HTTP响应头设置Set-Cookie
    - 服务器端设置后，客户端再次同一服务端发起请求时，就会携带这个Cookie并发到服务端上
    - 在域名相同(端口号不同的跨域)的情况下，Cookie是可以共享的，而其他跨域情况则无法共享

    > cookie跨域解决方案
    - (Nginx代理服务器 将两个服务器域名统一到一个反向代理服务器/
    - 设置域名 使用二级域名共享cookie需两个域名二级域名必须相同)
    1. 设置Nginx代理服务器 
        - 将两个服务器域名统一到一个反向代理服务器
    2. 设置域名 顶级域名与二级域名
        - (使用二级域名共享cookie需两个域名的二级域名必须相同)
        - 通过设置domain 顶级域名服务器与二级域名服务器之间那个设置都能生效 设置完毕后写回到客户端 用另一个服务器即可访问此cookie

    > cookie跨域解决方案
    1. 服务端将cookie写到客户端后 客户端对cookie进行解析 
    将token解析出来 此后请求都把这个Token带上即可
    2. 多个域名共享cookie 在写到客户端的时候设置cookie的domain
    3. 将Token保存在SessionStorage中
    (不依赖cookie就没有跨域问题)

    > Session
    - 基于Cookie实现的另一种记录服务器端和客户端会话状态的机制
    > Session缺点
    1. 当服务器访问量增加时 会存在很多Session 如果没有设置超时或销毁的话 很容易造成服务器崩溃等状况
    2. 服务端为集群或分布式时 用户登陆其中一台服务器 会将session保存到该服务器的内存中 但是当用户访问到其他服务器时 会无法访问 通常采用缓存一致性技术来保证可以共享 或者采用第三方缓存来保存session会不方便
    > 解决方案：
    - 存储在Tomcat容器中的 如果后端机器多台 多个机器间无法共享Session 使用Spring提供的分布式Session的解决方案将Session放在Redis中

    > Token：
    - 三种：
    1. 自定义的 token：开发者根据业务逻辑自定义的 token
    2. JWT：JSON Web Token，定义在 RFC 7519 中的一种 token 规范
    3. Oauth2.0：定义在 RFC 6750 中的一种授权规范，其实并不是一种 token，只是其中也有用到 token。
        
    - 访问API所需资源凭证 不需存储服务端 服务端只需根据客户端传来的token进行合法验证 
    访问资源接口
    (API-Application Programming Interface)
    所需要的资源凭证
    
    - 简单token组成
    - UID用户唯一的身份标识 time当前时间的时间戳 sign (签名 token的前几位以哈希算法压缩成的一定长度的十六进制字符串)


    > 使用Token目的：
    1. 减轻服务器压力
    2. 减少频繁的查询数据库
    3. 使服务器更加健壮    

    > Token机制
    1. 服务端如何根据token获取用户信息
        - 服务端生成token时 加入少量用户信息 比如用户id
        - 服务端接收到token之后 可以解析出这些数据 从而将token和用户关联起来
    2. 如何确保识别伪造的token
        - (代指token不是经过服务端来生成)
        - 一般情况下 建议放入token中的数据是不敏感的数据
        - 这样只要服务端使用私钥对数据生成签名 然后和数据拼接起来 作为token一部分即可 如JWT
        - 另一种模式 基于加密的算法 对数据进行加密 把加密的结果作为token
    3. 如何应对冒充情况
        1. 加干扰码
        2. 有效期
        3. token刷新

    > Token身份验证流程
    - 对称加密算法
    1. 加密
    - 将登录凭证做数字签名 加密后得到字符串作为token
    2. 解密
    - 拿到token串 做解密和签名认证 判断其有效性

    > Token有效期问题
    - 如果这个Token在服务端持久化(如存入数据库) 它就是一个永久的身份令牌
    解决操作过程中不能让用户感到Token失效问题
    1. 在服务器端保存Token状态 
        - 用户每次操作都会自动刷新(推迟)Token过期时间
        - Session就是采用这种策略保持用户登陆状态
        - 前后端分离 SPA 每秒可能发起很多次请求
        - 每次刷新过期时间代价大 为提升效率 减少消耗 把Token过期时间保存在缓存/内存中
    2. 使用Refresh Token 可以避免频繁的读写操作
        - 服务端不需要刷新Token过期时间 一旦Token过期 反馈给前端
        - 前端使用Refresh Token 申请一个全新的Token继续使用 服务器端只需在客户端请求更新Token时 对Refresh Token有效性检查 Refresh Token也有有效期 不过长一点

    > Refresh Token
    - Refresh Token及过期时间是存储在服务器的数据库中 只有在申请新的AccessToken时才会验证 不会对业务接口响应时间造成影响 也不需要向Session一样一致保存在内存中应对大量请求
    - 专用于刷新 access token 的 token Access Token的有效期比较 短当 Acesss Token 由于过期而失效时 使用 Refresh Token 就可以获取到新的 Token如果 Refresh Token过期就只能重新登陆了
    
    > Token无状态
        如果把所有状态信息都附加在Token上 服务器就可以不保存
        但服务端仍然要认证Token有效
        只要服务端能确认是自己签发的Token 
        且其信息未被改动过 就可认为Token有效
        签名可以实现上述所说
        此处签发和验证都是同一方
        (非同一方 非对称加密算法)
        对称加密算法即可达到要求
        对称加密算法比非对称算法快得多

    > Token单点登录
    - Token无状态后 单点登录就相对容易 前端拿到一个有效的Token 它就可以在任何同一体系的服务上认证通过 只要它们使用相同的密钥和算法来认证Token的有效性
    
    拦截验证
        客户端每一次请求 
        必须携带token UA 
        拦截器会对敏感资源的访问进行拦截
        然后根据UA解析Token
        解析不成功 
        表示Token与UA不匹配
        解析成功之后
        判断Token是否已过期
        如果是 拒绝服务
        所有都通过情况下
        拦截器方向 
        请求传达到业务服务者
    > Token服务器端有效性校验
    - 服务器端利用算法生成token 并将token存储在高并发的数据库中 并设置过期时间
    > Token优点(与Session相比)
    1. 不需要存储数据在服务端
    服务端只需要根据客户端传来的token进行合法验证
    通过后返回请求资源
    减轻服务器端的资源占用压力
    目前最流行的JWT(JSON WEB TOKEN)就是基于token实现
    以下以JWT标准介绍token
    2. 服务端不用存放token数据
    用解析token的计算时间换取session的存储空间
    从而减轻服务器的压力
    减少频繁查询数据库
    
    > Token特点
    1. 服务端无状态化 可扩展性好
    2. 支持移动端设备
    3. 安全
    4. 支持跨程序调用
    
    Token用处
    1. 防止表单重复提交
    2. 反CSRF
    3. 身份验证 单点登录

    如果你的用户数据可能需要和第三方共享
    或允许第三方调用API接口 用Token

    > JWT
    - JSON Web Token 目前最流行的跨域认证解决方案 一种认证授权机制 一种基于 JSON 的开放标准

    > JWT自包含
    - 负载payload中可以包含所需的所有用户部分的信息 可以避免对服务端数据库的多次查询

    > 服务器端JWT如何认证自身有效
    - 服务端获取header中的JWT 用base64URL算法解码各部分内容 并在服务端用同样的密钥和算法生成signature 与传过来的signature对比 验证JWT是否合法

    > 三个部分
    > 组成：
    - 一个 JWT token 是一个字符串，它由头部、载荷与签名三部分组成，中间用 . 分隔，形式如下：
    > base64(header).base64(json payload).signature
    1. Header 头部
        一个JSON对象 描述JWT的元数据
        {"alg":"HS256","typ":"JWT"}
        alg属性:(algorithm)
            签名的算法 默认是HMAC SHA256(写成HS256)
            或RSA
        typ属性:(type)
            这个令牌(token)的类型(type)
            JWT令牌统一写成JWT
        最后 将上面的JSON对象使用Base64URL转成字符串
    2. Payload 负载
        一个JSON对象 用来存放实际要传递的数据
        JWT规定了7个官方字段 供选用
        iss(issuer):签发人
        exp (expiration time)：过期时间
        sub (subject)：主题
        aud (audience)：受众
        nbf (Not Before)：生效时间
        iat (Issued At)：签发时间
        jti (JWT ID)：编号
        除了官方字段 还可以在这个部分定义私有字段
        { "sub": "1234567890", "name": "sssssss", "admin": true }
        JWT默认是不加密的 任何人都可以读到 不要把秘密信息放在这个部分
        这个JSON对象也要使用Base64URL算法转成字符串
    3. Signature 签名
        JWT的第三部分是一个签证信息
        该签证信息由三部分组成
        header(base64后)
        payload(base64后)
        secret(服务器端自定义的一个秘钥)
        这个部分需要base64加密后的header
        base64加密后的payload使用连接组成的字符串
        以及秘钥secret构成一个组合
        通过header中声明的加密方式对这个组合进行加密
        构成了jwt的第三部分
    > PS：
    - secret是保存在服务器端的 JWT的签发生成也是在服务器端的 secret就是用来进行JWT的签发和JWT的验证 它就是服务端的私钥 任何场景都不应该泄漏出去 一旦客户端得知这个secret 意味着客户端是可以自我签发JWT

    > 使用方式：
    1. 存放在cookie中
    当用户希望访问一个受保护的路由或者资源的时候，可以把它放在 Cookie 里面自动发送，但是这样不能跨域。
    2. 存放在localstorage中，添加到header中发送
    请求时放在 HTTP 请求头信息的 Authorization 字段里，使用 Bearer 模式添加 JWT Authorization: Bearer <token>
    3. 通过接口参数
    可以把 JWT 放在 POST 请求的数据体里，或者通过 URL 的 queryString 传输。
    
    > 认证流程：
    1. POST/user/login 输入用户名密码进行登录
    2. 服务器端使用密钥创建JWT
    3. 把JWT返回给浏览器
    4. 客户端将token保存在本地(通常使用localStorage/cookie)
    当用户希望访问一个受保护的路由或资源时 需要请求头的Authorization字段使用Bearer模式添加JWT
    4. 在发给服务器的请求头中发送JWT
    服务端保护路由将检查请求头Authorization中的JWT信息
    5. 检查JWT的签名 从JWT获取用户信息 减少查询数据库需要
    6. 把响应发送给客户端
    因为JWT是自包含的(内部包含了一些会话信息)
    因此减少了查询数据库的需求

    > Token/JWT优点：
    - (完全由应用管理 避开同源策略/避免CSRF攻击/实现无状态服务器 能在多个服务器间使用 可扩展性好)
    1. 完全由应用管理，可以避开同源策略
    2. 避免 CSRF(Cross Site Request Forgery) 跨站请求伪造 攻击
    3. 实现无状态服务端，能够在多个服务间使用，可扩展性好
    
    > Token/JWT为什么能避免CSRF攻击(服务器端验证header中的token信息 而非cookie信息)
    - 用户发请求给服务端时 前端使用JS将JWT放在header中手动发送给服务端 服务端验证header中的JWT字段 而非cookie信息 这样就避免了CSRF漏洞攻击
    
    > 自定义Token和JWT 的关系：
    > 相同点： 
    - 都是访问资源的令牌，都可以记录用户的信息，都是使服务端无状态化，都是只有验证成功后，客户端才能访问服务端上受保护的资源
    > 区别：
    - 服务端验证客户端发来的token信息要进行数据的查询操作；
    - JWT验证客户端发来的token信息就不用， 在服务端使用密钥校验就可以，不用数据库的查询。
    
    > 各种鉴权方式注意点
    1. 使用 cookie 注意点
        - (移动端一般不支持cookie session基于cookie实现用的也不多 移动端一般用token)
        1. 因为存储在客户端，容易被客户端篡改，使用前需要验证合法性
        2. 不要存储敏感数据，比如用户密码，账户余额
        3. 使用 httpOnly 在一定程度上提高安全性
        4. 尽量减少 cookie 的体积，能存储的数据量不能超过 4kb设置正确的 domain 和 path，减少数据传输
        5. cookie 无法跨域，子域名可以访问父域名
        6. 一个浏览器针对一个网站最多存 20 个Cookie，浏览器一般只允许存放 300 个Cookie
        7. 移动端对 cookie 的支持不是很好，而 session 一般基于 cookie 实现，所以移动端常用的是 token
    2. 使用 session 注意点
        - (sessionId可以跟在url参数后面即重写url session不一定非得靠cookie实现)
        1. 用户同时在线量较多时，session 存储在服务器会占据较多内存，需要定期清理过期的session
        2. 当网站采用集群部署的时候，会遇到多台 web 服务器之间如何做 session 共享的问题。因为 session是由单个服务器创建的，处理用户请求的服务器不一定是 那个创建 session 的服务器，那么该服务器就无法拿到之前已经放入到 session 中的登录凭证之类的信息了。
        3. 当多个应用要共享 session时，因为不同的应用可能部署的主机不一样需要在各个应用做好 cookie 跨域的处理。
        4. sessionId 是存储在 cookie 中的，假如浏览器禁止 cookie 或不支持 cookie ，一般会把 sessionId 跟在 url 参数后面即重写 url，所以 session 不一定非得需要靠 cookie 实现
    3. 使用 token 注意点
        1. 如果你认为用数据库来存储 token会导致查询时间太长，可以选择放在 内存当中，比如 redis(数据结构服务器) 很适合你对 token 查询的需求。
        2. token 完全由应用管理，所以它可以避开同源策略
        3. token 可以避免 CSRF 攻击(因为不需要 cookie 了)
        4. 移动端对 cookie 的支持不是很好，而 session 需要基于 cookie 实现，所以移动端常用的是 token
    4. 使用 JWT 时需要考虑的问题(默认不加密 可以生成原始Token后再用密钥加密一次)
        1. JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。
        2. JWT 不加密的情况下，不能将秘密数据写入 JWT。
        3. JWT 不仅可以用于认证，也可以用于交换信息 有效使用 JWT，可以降低服务器查询数据库的次数。
        4. JWT 最大的优势是服务器不再需要存储Session 使得服务器认证鉴权业务可以方便扩展
            这也是 JWT 最大的缺点：由于服务器不需要存储 Session 状态
            因此使用过程中无法废弃某个 Token 或者更改 Token 的权限
            也就是说一旦 JWT 签发了，到期之前就会始终有效，除非服务器部署额外的逻辑。
        5. JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限
            为了减少盗用，JWT的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。
        6. JWT 适合一次性的命令认证，颁发一个有效期极短的JWT
            即使暴露了危险也很小 由于每次操作都会生成新的 JWT，因此也没必要保存 JWT，真正实现无状态。
        7. 为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输
15. localStorage&sessionStorage
    - localStorage(Document源对象 本地存储 除非手动清除否则一直有效)和 
    - sessionStorage(session Storage对象 会话存储 会话结束时清除 浏览器关闭前有效)
    - 解决了cookie存储空间不足问题 
    - (5M|同源策略跨域无法访问|仅存储在客户端|以key和value形式存储数据)
    
    >localStorage
    - (Document源对象 本地存储 除非手动清除否则一直有效)和 
    
    > sessionStorage
    - (session Storage对象 会话存储 会话结束时清除 浏览器关闭前有效)---解决了cookie存储空间不足问题
    
    - cookie(在浏览器和服务器间来回传递) 
    - sessionStorage localStorage(不会自动把数据发给服务器，仅在本地保存)
    
    > localStorage如何存取对象
    - localStorage存储为字符串 使用JSON可以存储对象
    - JSON对象提供的parse和stringfy方法 将其他数据类型转化为字符串 再存储到storage中即可
    1. 存:
        ```
        var obj = {"name":"ergouzi","age":"16"}
        localStorage.setItem("userInfo",JSON.stringify(obj));
        ```
    2. 取:
        ```
        var user = JSON.parse(localStorage.getItem("userInfo"))
        ```
    3. 删除:
        ```
        localStorage.removeItem("userInfo);
        ```
    4. 清空：
        ```
        localStorage.clear();
        ```

    > 简介
    1. sessionStorage 和 localStorage 是 HTML5 新增的两个特性，这两个特性主要是用来作为会话存储和本地存储来使用的，解决了 cookie 存储空间不足的问题；
    2. sessionStorage 属性允许你访问一个 session Storage 对象，用于存储当前会话的数据，存储在 sessionStorage 里面的数据在页面会话结束时会被清除。
    页面会话在浏览器打开期间一直保持，并且重新加载或恢复页面仍会保持原来的页面会话。
    3. localStorage 属性允许你访问一个 Document 源(origin)的对象 Storage 用于存储当前源的数据，除非用户人为清除(调用 localStorage api 或则清除浏览器数据)， 否则存储在 localStorage 的数据将被长期保留。
    
    > 相同点
    1. 存储大小一般均为5M左右
    2. 都有同源策略限制，跨域无法访问
    3. 数据仅在客户端进行存储，并不参与和服务器的通信(不会随着 http 请求发送到服务器)
    4. 以 key 和 value 的形式进行存储数据， value 值必须为字符串，不为字符串会自动转型( value 如果是对象则需要转为 json 进行存储)
    
    > 不同点
    1. 生命周期
        1. localStorage 存储的数据是永久性的，除非用户人为删除否则会一直存在(调用 localStorage api 或则清除浏览器数据)。
        2. sessionStorage 存储的数据在当前会话结束时会被清除，一旦窗口或者标签页被关闭，那么所有通过 sessionStorage 存储的数据也会被删除。
    2. 作用域
        1. localStorage: 在同一个浏览器内，同源文档之间共享 localStorage 数据，可以互相读取、覆盖、清除(同浏览器限制、同源限制)
        2. sessionStorage: 与 localStorage 一样需要同一浏览器同源文档这一条件。除此之外 sessionStorage 的作用域还被限定在了窗口中，也就是说，只有同一浏览器、同一窗口的同源文档才能共享数据(同浏览器限制、同源限制、同标签页限制)
    
    5. cookie(在浏览器和服务器间来回传递) sessionStorage localStorage(不会自动把数据发给服务器，仅在本地保存)对比
        如何获取浏览器在网站的cookie
        获得浏览器在网站的cookie
        可以使不通过浏览器访问 也能使用自己的账号进行在浏览器上的操作
        1. 浏览器请求看
            控制台->network标签->doc分类
            name上点击右键 勾选domain 
            需domain和所访问网页域名相同
            点击域名相同的一个 弹出的小窗拉到中间 
            可以看见cookie的值
        2. 控制器用代码看
            控制台输入document.cookie 
            可输出cookie的值
        3. resource查看
            点击resource标签 找到下面的cookies
            点击本网站域名的cookie 该地方适合查看不适合复制
    共同点：
        都是保存在浏览器端，且同源的。 
    - 区别：
        1. cookie数据始终在同源的http请求中携带，即cookie在浏览器和服务器间来回传递。
            sessionStorage和localStorage不会自动把数据发给服务器，仅在本地保存。
        2. cookie数据不能超过4k(适合保存小数据)。 
        sessionStorage和localStorage容量较大，
        3. 数据有效期不同。
            sessionStorage：仅在当前浏览器窗口关闭前有效。
            localStorage：始终有效，窗口或浏览器关闭也一直保存，需手动清除；
            cookie只在设置的cookie过期时间之前一直有效，即使窗口或浏览器关闭。
        4. 作用域不同。
            - sessionStorage不在不同的浏览器窗口中共享；localStorage 在所有同源窗口中都是共享的；cookie也是在所有同源窗口中都是共享的。
    应用场景：
        localStorage：
            常用于长期登录（+判断用户是否已登录），适合长期保存在本地的数据。
        sessionStorage ：
            敏感账号一次性登录；
        cookies：
            与服务器交互。
16. 跨域相关(主要用来防止CSRF攻击)
    - (无论怎样的跨域资源获取方案 本质上都需要服务器端的支持)
    - (JSONP CORS Node中间件代理 nginx反向代理 postMessage)
    - cookie跨域解决方案
        1. 服务端将cookie写到客户端后 客户端对cookie进行解析 
        将token解析出来 此后请求都把这个Token带上即可
        2. 多个域名共享cookie 在写到客户端的时候设置cookie的domain
        3. 将Token保存在SessionStorage中

        (不依赖cookie就没有跨域问题)
        1. 设置Nginx代理服务器 
            将两个服务器域名统一到一个反向代理服务器
        2. 顶级域名与二级域名
            (使用二级域名共享cookie有一个限制条件
            两个域名的二级域名必须相同)
            通过设置domain
            顶级域名服务器与二级域名服务器之间那个设置都能生效
            设置完毕后写回到客户端 
            用另一个服务器即可访问此cookie

    > 为什么会出现跨域问题？
    - 出于浏览器的同源策略限制，浏览器会拒绝跨域请求。
    - 严格的说，浏览器并不是拒绝所有的跨域请求，实际上拒绝的是跨域的读操作。浏览器的同源限制策略是这样执行的：
    - 跨域并不是请求发不出去，请求能发出去，服务端能收到请求并正常返回结果，只是结果被浏览器拦截了。
        
    > 目的：
    - 主要是用来防止 CSRF(Cross-site Request forgery跨站请求伪造) 攻击的。
    简单点说，CSRF 攻击是利用用户的登录态发起恶意请求。
    
    > 什么情况才算作跨域？
    - 非同源请求，均为跨域。
    
    > 同源
    - 源(origin) = 协议(protocol)+端口(port)+主机/域名(host)
    
    > 为什么有跨域需求
    - 场景 —— 工程服务化后，不同职责的服务分散在不同的工程中，往往这些工程的域名是不同的，但一个需求可能需要对应到多个服务，这时便需要调用不同服务的接口，因此会出现跨域。

    > 跨域的五种实现方式  
    1. JSONP:(需服务器端配合|利用script标签没有限制跨域的漏洞|兼容性好实现简单|只支持get请求|容易受到XSS攻击)
    2. CORS(主要依靠后端配置|前端设置Access-Control-Allow-Origin即可开启CORS|前端分简单请求和非简单请求|存在兼容问题 支持POST请求/所有HTTP请求)
    3. Node中间件代理(跨域问题限制的是浏览器 搭建中间件服务器转发请求和响应)
    4. nginx反向代理 类似Node中间件服务器，通过nginx代理服务器实现。 实现方法：下载安装nginx，修改配置。
    5. postMessage(H5新增) 使用它来向其它的window对象发送消息，无论这个window对象是属于同源或不同源)

    > 五种跨域方法 JSONP CORS Node中间件代理 nginx反向代理 postMessage(H5新增)
    - 无论怎样的跨域资源获取方案 本质上都需要服务器端的支持
    1. JSONP(JSON with padding)--需要服务器端配合
        - JSONP:
            - 需服务器端配合|利用script标签没有限制跨域的漏洞|兼容性好实现简单|只支持get请求|容易受到XSS攻击)
            - 应用JSON的一种新方法，JSONP看起来和JSON差不多，只不过是被包含在函数调用的JSON，像这样：callback({name: 'nany'}
        - 实现原理：
            - 虽然因为同源策略的影响，不能通过XMLHttpRequest请求不同域上的数据（Cross-origin reads）。
            - 但是，在页面上引入不同域上的js脚本文件却是可以的（Cross-origin embedding）。因此在js文件载入完毕之后，触发回调，可以将需要的data作为参数传入。
            - 利用script标签没有跨域限制的漏洞，使得网页可以得到从其他来源动态产生的JSON数据（前提是服务器支持）。
        - 不支持post原因：
            - script标签只支持get请求
        - 实现方式(需前后端配合):
        - 优点:兼容性好（兼容低版本IE）,实现简单
        - 缺点：
            1. JSONP只支持GET请求；
            2. XMLHttpRequest相对于JSONP有着更好的错误处理机制       
            3. 容易受到XSS(跨站脚本)攻击 
    2. CORS Cross-origin resource sharing 跨域资源共享
    - (主要依靠后端配置|服务器端设置Access-Control-Allow-Origin即可开启CORS|前端分简单请求和非简单请求|存在兼容问题 支持post请求)  
    > 简单请求 同时满足以下两个条件
    1. 请求方法是 HEAD/GET/POST
    2. HTTP头信息字段为 
        - Accept/Accept-Language/Content-Language/Last-Event-ID/
        - Content-Tyep 
        1. application/x-www-form-urlencoded
        2. multipart/form-data
        3. text/plain)
        - (异步请求 前端分：简单请求/非简单请求(会先发送一次预检请求))
        - 一个W3C标准 允许浏览器向跨源服务器 发出XMLHttpRequest请求 从而克服AJAX只能同源使用的限制

    1. 浏览器会自动进行 CORS 通信，实现 CORS 通信的关键是后端。只要后端实现了 CORS，就实现了跨域。
    2. 服务端设置 Access-Control-Allow-Origin 就可以开启 CORS。
    3. 该属性表示哪些域名可以访问资源，如果设置通配符则表示所有网站都可以访问资源。
    4. 虽然设置 CORS 和前端没什么关系，但是通过这种方式解决跨域问题的话，会在发送请求时出现两种情况，分别为简单请求和复杂请求。
    
    > 原理：
    - 服务器端设置Access-Control-Allow-Origin以开启CORS。该属性表示哪些域名可以访问资源，如设置通配符则表示所有网站均可访问。
    
    - CORS 是W3C 推荐的一种新的官方方案，能使服务器支持 XMLHttpRequest 的跨域请求。CORS 实现起来非常方便，只需要增加一些 HTTP 头，让服务器能声明允许的访问来源。
    值得注意的是，通常使用CORS时，
    > 异步请求会被分为 
    1. 简单请求
    2. 非简单请求
    > 简单请求
    - 同时满足以下两大条件 就属于简单请求
    1. 请求方法是以下三种方法之一
        1. GET 获取数据
        2. POST 提交数据
        3. HEAD 本质和GET一样 区别在于HEAD不含有呈现数据 仅仅是HTTP头部信息
    2. HTTP头信息不超过以下几个字段
        1. Accept 
        2. application/x-www-form-urlencoded
        3. multipart/form-data
        4. text/plain
        - 表示客户端支持的数据类型 或客户端希望接收到的内容类型
        
        > Accept-Language
        - 表示客户端支持的语言格式(不是编码格式) 如中文/英文 通常浏览器直接发起请求时 浏览器会根据被设置的语言环境(默认语言) 来附加上该字段

        > Content-Language
        - 说明访问者希望采用的语言或语言组合 用户可根据自己偏好的语言来制定不同的内容

        Last-Event-ID

        > Content-Type(只限于三个值)
        1. application/x-www-form-urlencoded
        2. multipart/form-data
        3. text/plain

        - 这是为了兼容表单(form) 因为历史上表单一直可以发出跨域请求 AJAX的跨域设计就是 只要表单可以发 AJAX就可以直接发 凡是不同时满足上面两个条件 属于非简单请求 浏览器对这两种请求的处理是不一样的

        > 简单请求基本流程
        - 对于简单请求 浏览器直接发出CORS请求 具体来说就是在头信息中 添加一个Origin字段 Origin字段用来说明 本次请求来自哪个源 (协议+域名+端口) 服务器根据这个值 决定是否同意这次请求
        - 如果Origin指定的源 不在许可范围内 服务器会返回一个正常的HTTP回应浏览器发现 这个回应的头信息没有包含Access-Control-Allow-Origin字段知道出错 从而抛出一个错误被XMLHttpRequest的onerror回调函数捕获
        - PS:这种错误无法通过状态码识别 因为HTTP回应的状态码可能是200
        - 如果Origin指定的域名在许可范围内 服务器返回的响应 会多出几个头信息字段上面头信息中 有三个与CORS请求相关的字段 都以Access-Control开头

        > 非简单/复杂请求 
        > 预检请求
        - 是那种对服务器有特殊要求的请求 比如请求方法是PUT/DELETE 或者Content-Type字段类型是application/json
        - 非简单请求的CORS请求 会在正式通信之前 增加一次HTTP查询请求 称为预检请求
        - 浏览器先询问服务器 
        - 当前网页所在域名是否在服务器许可名单之中 以及可以使用哪些HTTP动词和头信息字段 只有得到肯定答复 浏览器才会发出正式的XMLHttpRequest请求 否则就报错

        - 预检请求用的请求方法是OPTIONS 表示这个请求是用来询问的 头信息中 关键字段是Origin 表示请求来自哪个源 除了Origin字段 预检请求的头信息包含两个特殊字段
        > 预检请求回应
        - 服务器受到预检请求以后 检查Origin Access-Control-Request-Method         Access-Control-Request-Header字段后 确认允许跨域请求 就可以做出回应
        
        - 上面的HTTP回应中 关键的是Access-Control-Allow-Origin字段 表示http://api.bob.com可以请求数据 该字段也可以设为* 表示同意任何跨源请求

        - 如果服务器否定了预检请求 会返回一个正常的HTTP回应 但是没有任何CORS相关的头信息字段 这时 浏览器就会认定 服务器不同意预检请求 因此触发一个错误 被XMLHttpRequest对象的onerror回调函数捕获
        > 浏览器的正常请求和回应
        - 一旦服务器通过了预检请求 以后每次浏览器正常的CORS请求 都与简单请求一样 会有一个Origin头信息字段 服务器回应 也都会有一个Access-Control-Allow-Origin信息字段
        > 优缺点
        1. 使用简单方便，更为安全
        2. 支持 POST 请求方式，
        3. CORS是一种新型的跨域问题的解决方案，存在兼容问题，仅支持IE 10以上
        > JSONP和CORS比较
        1. CORS与JSONP使用目的相同 但是比JSONP强大
        2. JSONP只支持GET请求 CORS支持所有类型的HTTP请求
        3. JSONP优势在于支持老式浏览器 以及可以向不支持CORS的网站请求数据
    3. Node中间件代理(跨域问题限制的是浏览器 搭建中间件服务器转发请求和响应)
        > 原理：同源策略仅是浏览器需要遵循的策略，故搭建中间件服务器转发请求与响应，达到跨域目的。
        - 类似于将跨域请求交给第三方，第三方去访问指定的网络，获取数据然后返回
    4. nginx反向代理 类似Node中间件服务器，通过nginx代理服务器实现。 实现方法：下载安装nginx，修改配置。
        - 正向代理：隐藏了客户端
        - 反向代理：隐藏了服务端(如VPN)
        > 原理： 类似Node中间件服务器，通过nginx代理服务器实现。
        - 实现方法：下载安装nginx，修改配置。
    5. postMessage(H5新增) 使用它来向其它的window对象发送消息，无论这个window对象是属于同源或不同源
        1. window.postMessage(message,targetOrigin) 方法是html5新引进的特性
        2. 可以使用它来向其它的window对象发送消息，无论这个window对象是属于同源或不同源
        3. 目前IE8+、FireFox、Chrome、Opera等浏览器都已经支持window.postMessage方法
    6. WebSocket
        - webSocket本身不存在跨域问题 可以利用webSocket进行非同源之间的通信
        - 原理：利用webSocket的API 可以直接new一个socket实例 然后通过open方法内send要传输到后台的值 也可以利用message方法接收后台传来的数据 后台是通过new WebSocket Server({port:3000})实例 利用message接收数据 利用send向客户端发送数据

        - JS创建了web socket之后，会有一个HTTP请求发送到浏览器以发起连接。取得服务器响应后，建立的连接会使用HTTP升级从HTTP协议交换为web sockt协议。
17. axios是什么 底层是如何实现的
    - 一个基于Promise的HTTP库 可以用在浏览器和node.js中
    - 本质是XMLHttpRequests请求 即AJAX请求
    - 基于Promise的用于浏览器和Nodejs的HTTP客户端

    > 特点：
    1. 从浏览器中创建XMLHttpRequests
    2. 从node.js创建http请求
    3. 支持Promsie API
    4. 拦截请求和响应
    5. 转换请求数据和响应数据
    6. 取消请求
    7. 自动转换JSON数据
    8. 客户端支持防御XSRF
    
    > 浏览器支持
    - 支持IE8及以上的浏览器

    > 基本使用
    - axios提供了两种不同的形式来发送HTTP请求
    1. 通过axios(config)方法
    2. 分别通过axios对象提供的与HTTP对应的方法发起请求
        1. axios.method(url,data,config)

    > 使用方法:
    1. 执行get数据请求
    2. 执行post数据请求
    3. axios API通过相关配置传递给axios完成请求
    4. axios的并发 axios.all axios.spread
    5. axios包含所有请求方式函数的封装
    
    > 初步封装一个类似于axios的函数
    1. 执行返回一个promise
    2. 能够通过create方法配置初始化参数
    3. 包含所有的AJAX方法并返回Promise对象
    4. 支持Promise.all并能用spread处理
    安装：
        使用npm
            npm install axios
    > 实现原理：
    1. axios原理还是属于XMLHttpRequest 因此需要实现一个AJAX
    2. 需要一个Promise对象对结果进行处理

    > axios api的使用
    - axios方法接收一个对象 这个对象包含了一些对请求的配置 axios会根据这些配置来发送对应的HTTP请求
    - 最基本的配置项应该包括
    1. method 请求的方法(可选值 get post等)
    2. url 请求的地址(必须项)
    3. data请求发送的数据(post的部分请求需要)
    - PS：默认的请求方法是get所以如果是get请求可以不设置method
    - 请求响应的处理在then和catch回调中 请求正常会进入then 请求一场则会进catch
    > axios有什么特性
    1. 从浏览器中创建XMLHttpRuquests
    2. 是从node.js中创建http请求
    3. 支持Promise API
    4. 拦截请求和响应
    5. 转换请求数据和响应数据
    6. 取消请求
    7. 自动转换JSON数据
    8. 客户端支持防御XSRF
    > axios可以用在浏览器和nodejs中是因为
    1. 它会自动判断当前环境是什么 
    2. 如果是浏览器 就会基于XMLHttpRequests实现axios 
    3. 如果是nodejs环境 就会基于node内置核心模块http实现axios
    > axios基本原理
    1. axios还是属于XMLHttpRequest 因此需要实现一个AJAX 或者基于HTTP
    2. 还需要一个promise对象来对结果进行处理
    > 请求和响应拦截器
    1. 请求拦截器 在发送请求之前做点什么 对请求错误做点什么
    2. 响应拦截器 对响应数据做点什么 对相应错误做点什么
    3. axios.interceptors.response.use & axios.interceptors.request.use来触发拦截器执行use方法
18. AJAX
    > AJAX
    - AJAX是'Asyncchronous JavaScript And XML'缩写(即异步的JS和XML)
    - 一种实现无页面刷新获取服务器资源的混合技术 一种能够实现局部网页刷新的技术 使网页异步刷新
    
    > 实现
    1. 创建XMLhttpRequest核心对象|
    2. open方法打开与服务器连接|
    3. send方法发送请求 POST请求时 需设置额外请求头|
    4. 监听服务器响应 接收返回值)
    - (open打开连接 send发送请求 监听服务器响应 接收返回值)

    > AJAX意义：
    1. 使浏览器在不刷新页面的情况下获取服务器响应
    2. 大大提升互联网用户使用体验
    3. AJAX请求获取的是数据而不是HTML文档 节省网络带宽
    
    > AJAX获取数据
    - 通常使用API与各式各样的数据库交互 服务器 AJAX技术核心--XMLHttpRequest对象
    - XMLHttpRequest对象是浏览器提供的一个API 用来顺畅地向服务器发送请求并解析服务器响应 整个过程中 浏览器页面不会被刷新
    1. XMLHttpRequest只是一个JS对象 
        - 确切地说是一个构造函数 特殊之处只在于它是由客户端(即浏览器)提供的(而不是JavaScript原生的) 除此之外它有属性 方法 需要通过new关键字进行实例化
    2. XMLHttpRequest对象不断被扩展
        const xhr = new XMLHttpRequest()
        属性
            .responseText:包含响应主体返回文本
            .responseXML:如果响应的内容类型是text/xml或application/xml 该属性将保存包含相应数据的XML DOM文档
            .status:响应的HTTP状态
            .statusText:HTTP状态的说明
            .readyState:请求/响应过程的当前活动阶段
        方法
            .open():准备启动一个AJAX请求
            .setRequestHeader():设置请求头部信息
            .send()发送AJAX请求
            .getResponseHeader():获得响应头部信息
            .getAllResponseHeader():获得一个包含所有头部信息的长字符串
            .abort():取消异步请求
        浏览器为该对象提供一个onreadystatechange监听事件 
        每当XML实例的readyState属性变化时 会触发该事件的发生

    > AJAX请求时 如何解释json数据
    - 字符串形式的JSON：eval("("+ajax.response+")")
    - 本地的JSON文件：JSON.parse(data)

    > 概念：
    > XML 
    - 一种特征类似HTML用来描述 数据是什么并承载数据的标记语言
    - JSON发明之前 人们大量使用XML作为数据传输的载体
    - Extensible Markup Language缩写 (即:可扩展标记语言)
    - 一种特征类似HTML 用来描述 数据是什么 并承载数据的标记语言
    - JSON只是一种数据格式 JSON发明之前 人们大量用XML作为数据传输的载体 而如今情况发生了些变化
    - JSON这种类似字符串对象的轻量级的数据格式越来越受开发者的青睐 几乎变成了AJAX技术的标准数据格式 
    - PS:JSON不是XML的替代品两者各自有其适应的场景
    
    > 无页面刷新
    - 互联网最重要功能在于资源交换
    - 有没有办法在页面数据变动时 只向服务器请求新的数据 并且在阻止页面刷新的情况下动态替换页面中展示的数据呢 --AJAX
    
    > AJAX技术 
    - 通过阻止浏览器接受响应时刷新页面提升互联网用户使用体验
    - 使开发者能以更微观视角重新思考互联网应用的构建
    - 开发者将在“数据”层面而不是“资源”层面以更高的自由度构建网站和Web应用。
    
    > 混合技术
    - AJAX技术不只是操作XMLHttpRequest对象发起异步请求 
    - 是为了实现无页面刷新的资源获取的一些列技术的统称
    - 这些技术包括
        1. JS：用来获取数据后 通过操作DOM或其他方式达到目的
        2. 客户端(即浏览器)提供的实现异步服务器通信的XMLHttpRequest对象
        3. 服务器端允许浏览器向其发起AJAX请求的相关设置
    
    > PS:明白AJAX并不只是操作XMLHttpRequest对象 对初学者而言十分必要
    > DRY
    - Don't Repeat Yourself
19. Form表单提交和AJAX提交区别
    - (安全性一样 安全性与提交文件的业务处理有关 与提交方式无关)
    - (AJAX网页局部刷新 异步请求/Form放弃本页面 新建一个页面
    - AJAX必须使用JS实现 由JS引擎解释/Form浏览器自带 使用JS与否都可以提交表单)
    1. 使用场景
        - 安全性一样 都是发送HTTP协议 安全性与提交文件的业务处理(格式检测 防注入)有关 与提交方式无关
        - Form表单提交 一般登录 点击提交触发submit事件 会使页面发生跳转 页面的跳转等行为的控制往往在后端 后端控制页面的跳转及数据的传递
        - AJAX提交 通过JS来提交请求 请求与响应均由JS引擎处理 页面不会刷新 不希望页面跳转/将控制权放在前端 通过JS操作页面跳转或数据变化 AJAX有个隐藏问题 浏览器不保存密码 不符合用户习惯
        - 理想方式
            建立隐藏的iframe
            把form标签的target指向iframe 
            然后检测iframe状态
    > 比较
    1. AJAX在提交请求接收时 都是异步进行 网页不需要刷新 只刷新页面局部 不关心也不影响其他部分的内容
        Form提交则是新建一个页面 哪怕是提交给自己本身的页面也需要刷新 为了维持页面用户对表单的状态改变 要在控制器和模板之间传递更多参数以保持页面状态
    2. AJAX提交时 是在后台新建一个请求
        Form是放弃本页面 然后再请求
    3. AJAX必须要用JS实现 存在调试麻烦 浏览器兼容问题
    不启动JS的浏览器 无法完成操作
        Form表单是浏览器自带的 无论是否开启JS都可以提交表单
    4. AJAX在提交 请求接收时 整个过程都需要使用程序对其进行数据处理 
        Form表单提交 根据表单结构自动完成 不需要代码干预 用submit提交
    > 其他方面
        关于输入内容的校验 
        AJAX可以在获取到元素内部用程序判断 
        Form表单的属性中有校验的字段
        easyui jeecg等中都封装 用户只需添加正则表达式的校验规则
20. XSS
    (Web页面中插入恶意代码 用户浏览该页面 恶意代码被执行)
    (漏洞关键 寻找参数未过滤的输出函数)
    (反射型XSS 非持久化 不存储在服务器 用户点击链接触发
    存储型XSS 持久化 存储在服务器 用户浏览触发 非常危险 容易造成蠕虫大量盗取cookie
    DOM型XSS 使用相对较少 特殊 常见的漏扫工具都无法检测出来)
    (cookie设置HttpOnly标签/过滤标签/转义编码)
    1. 定义
        跨站脚本攻击
            (通过PHP输出函数将JS代码输出到HTML页面)
            恶意攻击者往Web页面里插入恶意Script代码 用户浏览该页时 嵌入其中Web里面的Script代码被执行 从而达到恶意攻击用户的目的
            xss漏洞通常
                通过php的输出函数将javascript代码输出到html页面中
                通过用户本地浏览器执行的
                xss漏洞关键寻找参数未过滤的输出函数。
            常见的输出函数 echo printf print print_r sprintf die var-dump var_export.
    2. 三类
        1. 反射型XSS
            (非持久化 不存储在服务器 用户点击链接触发)
            攻击者事先制作好攻击链接 需要欺骗用户自己去点击链接才能触发XSS代码
            （服务器中没有这样的页面和内容）
            一般容易出现在搜索页面
            原理：
                黑盒测试中，这种类型比较容易通过漏洞扫描器直接发现，我们只需要按照扫描结果进行相应的验证就可以了。
                相对的在白盒审计中， 我们首先要寻找带参数的输出函数，接下来通过输出内容回溯到输入参数，观察是否过滤即可。
                通过它我们知道输入javascript代码是可以被执行的，当我们输入一些其他函数，比如document.cookie就可以成功盗取用户的cookie信息，或者读取用户浏览器信息等，为我们进一步深入攻击做铺垫。
            防范：
                htmlentities()函数对用户输入的<>做了转义处理 恶意代码当然也就没法执行了。
                还有其他过滤函数
        2. 存储型XSS(持久化)(一次提交之后，每当有用户访问这个页面都会受到XSS攻击，危害巨大。)
            代码是存储在服务器中的
            如在个人信息或发表文章等地方，加入代码，如果没有过滤或过滤不严，那么这些代码将储存到服务器中，每当有用户访问该页面的时候都会触发代码执行，这种XSS非常危险，容易造成蠕虫，大量盗窃cookie（虽然还有种DOM型XSS，但是也还是包括在存储型XSS内）。
                原理：
                    和反射性XSS的即时响应相比，存储型XSS则需要先把利用代码保存在比如数据库或文件中，当web程序读取利用代码时再输出在页面上执行利用代码。但存储型XSS不用考虑绕过浏览器的过滤问题，屏蔽性也要好很多。
                    1.攻击者发送恶意脚本请求
                    2.恶意脚本被保存到数据库中
                    3.用户正常浏览页面
                    4.从数据库读取恶意脚本
                    5.将恶意脚本返回用户 构造页面
                    6.浏览器解析 执行恶意脚本 发起攻击
                防范：
                    存储型XSS对用户的输入进行过滤的方式和反射型XSS相同，这里我们使用htmlspecialchars()函数进行演示：
                    htmlentities() :把预定义的字符 "<" （小于）和 ">" （大于）转换为 HTML 实体
                    htmlspecialchars和htmlentities的区别：
                        htmlspecialchars 只转义 & 、" 、' 、< 、> 这几个html代码，而 htmlentities 却会转化所有的html代码，连同里面的它无法识别的中文字符也会转化。
        3. DOM型XSS(该种XSS用的相对较少 由于其特殊性 常见的漏扫工具都无法检测出来)
            基于文档对象模型Document Objeet Model，DOM)的一种漏洞
            DOM是一个与平台、编程语言无关的接口，它允许程序或脚本动态地访问和更新文档内容、结构和样式，处理后的结果能够成为显示页面的一部分
            DOM中有很多对象，其中一些是用户可以操纵的，如uRI ，location，refelTer等
            客户端的脚本程序可以通过DOM动态地检查和修改页面内容
            它不依赖于提交数据到服务器端，而从客户端获得DOM中的数据在本地执行，如果DOM中的数据没有经过严格确认，就会产生DOM XSS漏洞。
        解释
            HttpOnly是加在cookie上的一个标识 用于告诉浏览器不要向客户端脚本(document.cookie/其他)暴露cookie
        - 防范
            1. 设置HttpOnly避免cookie劫持危险
            2. 过滤 对诸如<script><img><a>等标签进行过滤
            3. 转义编码 一些常见的符号 如<>在输入时要对其进行转换编码
            4. 限制 对一些可以预期的输入可以通过限制长度强行截断进行防御
        总结：
            XSS漏洞原理和相关函数 eval() assert() preg_replace() 回调函数 动态执行函数
            XSS漏洞的防范
21. CSRF(Cross Site Request Forgery(伪造))/XSRF
    (XSS 利用合法用户获取其信息)
    (CSRF 伪装成合法用户发起请求 原理和XSS正好相反)
    (防范：post修改信息/不让第三方网站访问cookie/请求时附带验证信息 token 验证码)
    原理和XSS正好相反
        XSS(Cross Site Script 跨站脚本攻击)利用合法用户获取其信息
        CRSF(Cross Site Request Forgery跨站请求伪造)伪装成合法用户发起请求
    如何防范：
        1.使用post 不使用get修改信息
        2.不让第三方网站访问到用户cookie 阻止第三方网站请求接口
        3.请求时附带验证信息 如验证码/Token

        4.HTTP头中自定义属性并验证
        5.验证HTTP Referer字段
        6. 在表单中预先植入一些加密信息，验证请求是此表单发送
22. sql注入(SQL injection)
    - 原理：
        通过把sql命令插入到Web表单递交或输入域名或页面请求的查询字符串 最终达到欺骗服务器执行恶意SQL命令  
        未授权情况下 非法访问数据库信息
    - 防范(参数转义)
        1. 杜绝用户提交的参数入库且执行
        2. 代码层 不准出现SQL语句
        3. web输入参数处 对所有参数做sql转义
        4. 上线测试 需要使用sql自动注入工具进行所有页面sql注入脚本
23. MITM
    (Man-in-the-MiddleAttck-中间人攻击)攻击
    (HTTPS/不使用公共网络发送敏感信息/不点击恶意链接和电子邮件)
    流程：
        1.服务器向客户端发送公钥 攻击者截获公钥 保留在自己手上
        2.攻击者自己生成一个伪造公钥 发给客户端
        3.客户端收到伪造的公钥 生成加密hash值发给服务器
        4.攻击者获得加密hash值 用自己的私钥解密获得真秘钥。
        5.生成假的加密hash值 发给服务器
        6.服务器用私钥解密获得假秘钥。
        7.服务器用假秘钥加密传输信息
    工作方式：
        1.嗅探
            嗅探和数据包嗅探是一种用于捕获流进和流出系统/网络的数据包的技术 网络中的数据包嗅探就好像电话中的监听 如果使用正确 数据包嗅探是合法的 许多公司处于安全目的都会使用它
        2.数据包注入
            这种技术中 攻击者会将恶意数据包注入常规数据中
            这样用户便不会注意到文件/恶意软件 因为它们是合法通讯流的一部分
            在中间人攻击和拒绝式攻击中 这些文件是很常见的
        3.会话劫持
            在你登录进你的银行账户和退出登录这一段期间称为一个会话 这些会话通常都是黑客攻击目标 因为它们包含潜在的重要信息 大多数案例中 黑客会潜伏在会话中 并最终控制它 这些攻击的执行反射光hi有多种
        4.SSL剥离
            SSL剥离/SSL降级攻击是MITM攻击的一种十分罕见的方式 也是最危险的一种 SSL/TSL证书通过加密保护通讯安全 在SSL剥离攻击中 攻击者使SSL/TLS连接剥落 随之协议从安全HTTPS变成不安全HTTP
    防范：(HTTPS/不使用公共网络发送敏感信息/不点击恶意链接和电子邮件)
        1.确保在URL前你所访问的网站有HTTPS
        2.点击电子邮件前 检查电子邮件发送人
        3.如果你是一个网站检查员 你应当执行HSTS协议
        4.不要在公共WIFI网络上购买/发送敏感数据
        5.确保你的网站没有任何混合内容
        6.如果你的网站使用了SSL
        确保你禁用了不安全的SSL/TLS协议 
        应当只启动TLS1.1和TLS1.2
        7.不要点击恶意链接或电子邮件
        8.时不要下载盗版内容
        9.将安全工具正确安装在系统上
25. Fetch API与传统Request的区别
    1. fetch 符合关注点分离，使用 Promise，API 更加丰富，支持 Async/Await 
    2. 语意简单，更加语意化
    3. 可以使用 isomorphic-fetch ，同构方便
    传统AJAX时代 进行API等网络请求都是通过XMLHttpRequest或者封装后的框架进行网络请求 然而配置和调用方式混乱 对新手不友好
    - Fetch优点
        1. 语法简介 更加语义化 业务逻辑更清晰
        2. 基于标准Promise实现 支持async/await
        3. 同构方便 使用isomorphic-fetch
    Promise简介
        Fetch API是基于Promise设计的
    fetch方法返回一个Promise对象 根据Promise API特性 
        Fetch可以方便地使用then方法将各个处理逻辑串起来
        使用Promise.resolve()/Promise.reject()方法
        将分别返回肯定结果的Promise或否定结果地Promise
        从而调用下一个then/catch 一旦then中的语句出现错误
        也将跳到catch中
    fetch请求常见数据格式
        1.fetch请求本地文本数据
        2.fetch请求本地JSON数据
        3.fetch请求网络接口
26. DNS原理
    网络通讯大部分是基于TCP/IP 而TCP/IP是基于IP地址的
    所以计算机在网络上进行通讯时只能识别IP地址 而不能认知域名
    DNS
        提供服务将主机名和域名转换为IP地址
    DNS过程
        DNS是应用层协议 为其他应用层协议工作
        包括不限于HTTP和SMTP和FTP
        用于将用户提供的主机名解析为IP地址
    具体过程
    (用户主机运行DNS客户端/
    浏览器从url中抽取出域名片段 将其传递给DNS应用的客户端/
    DNS客户端向DNS服务器端发送查询报文/
    DNS客户端最终收到一份回答报文 包含该主机对应IP地址/
    浏览器收到来自DNS的IP地址 向该IP地址定位的HTTP服务器发起TCP连接)
        1.用户主机上运行着DNS的客户端，就是我们的PC机或者手机客户端运行着DNS客户端了
        2.浏览器将接收到的url中抽取出域名字段，就是访问的主机名，比如http://www.baidu.com/ 并将这个主机名传送给DNS应用的客户端
        3.DNS客户机端向DNS服务器端发送一份查询报文，报文中包含着要访问的主机名字段（中间包括一些列缓存查询以及分布式DNS集群的工作）
        4.该DNS客户机最终会收到一份回答报文，其中包含有该主机名对应的IP地址
        5.一旦该浏览器收到来自DNS的IP地址，就可以向该IP地址定位的HTTP服务器发起TCP连接
27. 网关
    > 三层CS架构
    > 客户端 服务端 数据层
    - 随着多端设备的兴起 多端开发逐渐成为主流 虽然处于不同端 但相同的业务都会使用同一份数据
    - 当不同端请求走到后台 后台去数据库查询数据 并且将数据拼接返回给前端

    > 四层CS架构
    > 客户端 网关层 服务层 数据层
    - 为保证服务可用性 接口性能 数据安全 后端开发往往要考虑缓存 限流 降级 鉴权等 这些功能并不和某个特定业务强关联 并且在各个服务中都是通用的
    - 按照分层架构的思想 将这些功能放在单独一层分为网关 提供功能的服务 称为网关服务

    > 技术选型选择Node
    > 优点
    1. 异步非阻塞的编程模型 async/await语法让开发者用同步写法写出异步代码 本身适合IO密集型场景 
    2. 不需要太多前置知识就能写出性能较高的代码
    3. TS的推广 使得类型系统被应用在大型JS项目中
    > 缺点
    1. 单线程瓶颈限制
    2. Nodejs进行数据计算性能非常低
    3. 相较于Java 官方没有支持高级的数据结构和算法
28. content-length与Transfer-Encoding
    > content-length
    - HTTP消息长度 用十进制数字表示的八位字节的数目 是Headers中常见的一个字段
    - Content-Length 应该是精确的 否则就会导致异常
    - HTTP1.0中这个字段可有可无
    - Conent-Length首部指出报文中实体主体的字节大小
    - 这个大小是包含了所有内容编码的
    - 比如 对文本文件进行了gzip压缩 
    - Content-Length首部指的就是压缩后的大小而不是原始大小
    
    > content-length工作
    - content-length使用十进制的数字表示消息的长度 服务端/客户端通过它来得知后续要读取消息的长度

    > content-length>实际长度
    - 服务端/客户端读取到消息结尾后 会等待下一个字节 自然会无响应直到超时
    - 响应消息中content-length超过实际长度也是同样

    > content-length<实际长度
    - 首次请求的消息会被截取
    - 如参数为param = ipdaedead Content-Length为10 这次请求的消息会被截取为param = ipda
    - 第二次请求 服务端抛出异常(connection:keep-alive)
    ```
    Request method '' not support
    ```
    - 如果使用connection:close 
    - 每一次的请求都被截断 但不会产生解析混乱

    > 不确定Content-Length
    - Content-Length首部指示出报文中实体主体的字节大小
    - 但如在请求处理完成之前无法获取消息长度
    - 就无法明确指定Content-Length
    - 此时应该使用Transfer-Encoding:chunkde

    > Transfer-Encoding:chunkde
    - 数据以一系列分块的形式进行发送
    - Content-Length 首部在这种情况下不被发送. 在每一个分块的开头需要添加当前分块的长度, 以十六进制的形式表示，后面紧跟着 \r\n , 之后是分块本身, 后面也是\r\n. 终止块是一个常规的分块, 不同之处在于其长度为0.
    > 主要应用场景
    - 传输大量数据 但是请求在没有被处理完之前响应的长度是无法获取的
    - 如 当需要用从数据库中查询获得的数据生成一个大的HTML表格 需要传输大量的图片等
    > 小结
    1. Content-Length如果存在且生效 必须是正确的 否则会发生异常(大于实际值会超时 小于实际值会截断并可能导致后续的数据解析混乱)
    2. 如果报文中包含Transfer-Encoding:chunked首部 则Content-length将被忽略
29. websocket(H5的一种新协议 被用做即时通讯 以代替轮询)
    > 定义：
    - (H5一种新协议 实现浏览器和服务器全双工通信 一开始握手需借助HTTP请求完成 请求完成单独建立一条TCP通信信道进行数据传送 被用作即时通讯 代替轮询)
    - WebSocket protocol(应用层协议)是HTML5一种新的协议 它实现了浏览器与服务器全双工通信(full-duplex) 一开始的握手需要借助HTTP(非持久化单向)请求完成 单独建立一条TCP的通信信道进行数据传送 被用作即时通信代替轮询
    
    > 用途：
    - 网站上的即时通讯是很常见的，比如网页的QQ 微信等 按照以往的技术能力通常是采用轮询等技术解决。
    
    > 原理：
    1. (HTTP1.x协议是非持久化的，单向的网络协议，在建立连接后只允许浏览器向服务器发出请求后，服务器才能返回相应的数据 浪费流量和服务器端资源)
    2. (连接之后服务器和浏览器都可以主动向对方发出请求 保持连接+心跳ping pong)
    > 轮训
    3. 当需要即时通讯时，通过轮询在特定的时间间隔（如1秒），
    4. 由浏览器向服务器发送Request请求，然后将最新的数据返回给浏览器。
    5. 缺点：会导致过多不必要的请求，浪费流量和服务器资源，每一次请求、应答，都浪费了一定流量在相同的头部信息上
    6. WebSocket中，只需要服务器和浏览器通过HTTP协议进行一个握手的动作，然后单独建立一条TCP的通信通道进行数据的传送。
    7. WebSocket同HTTP一样也是应用层的协议，但是它是一种双向通信协议，是建立在TCP之上的 广泛被用来做即时通讯，以替代轮询。
     
    > 与HTTP不同：
    1. WebSocket 是一种双向通信协议，在建立连接后，WebSocket 服务器和Browser/Client Agent 都能主动的向对方发送或接收数据，就像 Socket 一样。
    2. WebSocket 需要类似TCP的客户端和服务器端通过握手连接，连接成功后
    
    > WebSocket是类似Socket的TCP长连接的通讯模式，一旦 WebSocket 连接建立后，后续数据都以帧序列的形式传输。
    在客户端断开 WebSocket 连接或 Server 端断掉连接前，不需要客户端和服务端重新发起连接请求。
    - 在海量并发及客户端与服务器交互负载流量大的情况下，极大的节省了网络带宽资源的消耗，有明显的性能优势，且客户端发送和接受消息是在同一个持久连接上发起，实时性优势明显。
    
    > 连接过程&特点：
    > 连接过程：(TCP三次握手建立TCP连接 HTTP握手 HTTP回馈 TCP通道)
    1. 浏览器、服务器建立TCP连接，三次握手。这是通信的基础，传输控制层，若失败后续都不执行。
    2. TCP连接成功后，浏览器通过HTTP协议向服务器传送WebSocket支持的版本号等信息。（开始前的HTTP握手）
    3. 服务器收到客户端的握手请求后，同样采用HTTP协议回馈数据。
    4. 当收到了连接成功的消息后，通过TCP通道进行传输通信。
    
    > 特点：
    1. 建立在 TCP 协议之上，服务器端的实现比较容易。
    2. 与 HTTP 协议有着良好的兼容性。默认端口也是80和443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。
    3. 数据格式比较轻量，性能开销小，通信高效。
    4. 可以发送文本，也可以发送二进制数据。
    5. 没有同源限制，客户端可以与任意服务器通信。
    6. 协议标识符是ws（如果加密，则为wss），服务器网址就是 URL
    
    > 保持连接+心跳(客户端和服务器端长时间没有数据往来 但仍需要保持连接 此时 可以采用ping+pong心跳实现)
    - WebSocket为了保持客户端、服务端的实时双向通信，需要确保客户端、服务端之间的TCP通道保持连接没有断开。然而，对于长时间没有数据往来的连接，如果依旧长时间保持着，可能会浪费包括的连接资源。
    - 但不排除有些场景，客户端、服务端虽然长时间没有数据往来，但仍需要保持连接。这个时候，可以采用心跳来实现。
    - 发送方->接收方：ping
    - 接收方->发送方：pong
    ping、pong的操作，对应的是WebSocket的两个控制帧，opcode分别是0x9、0xA。
    举例，We
    > 主要API
    1. 构造函数
        WebSocket 对象作为一个构造函数，用于新建 WebSocket 实例。
        const ws = new WebSocket('ws://localhost:80');
    2. webSocket.readyState
        readyState属性返回实例对象的当前状态
            CONNECTING：值为0，表示正在连接。
            OPEN：值为1，表示连接成功，可以通信了。
            CLOSING：值为2，表示连接正在关闭。
            CLOSED：值为3，表示连接已经关闭，或者打开连接失败。
    3. webSocket.onopen
        实例对象的onopen属性，用于指定连接成功后的回调函数。
    4. webSocket.onclose
        实例对象的onclose属性，用于指定连接关闭后的回调函数。
    5. webSocket.onmessage
        实例对象的onmessage属性，用于指定收到服务器数据后的回调函数。
    6. webSocket.send
        实例对象的send()方法用于向服务器发送数据。
    7. webSocket.onerror
        实例对象的onerror属性，用于指定报错时的回调函数。
30. Webworker
    > workder主线程
    1. 通过worker = new worker
    > 作用
    1. 为JS创造多线程环境 允许主线程创建Worker线程 
    2. 将一些任务分配给后者运行
    3. 主线程运行同时 Worker线程在后台运行 两者互不干扰 等到Worker线程完成计算任务 再把结果返回给主线程
    > 好处
    - 一些计算密集型或高延迟的任务 被Worker线程负担 主线程(通常负责UI交互)会很流畅 不会被阻塞或拖慢
    > Worker线程一旦新建成功
    1. 就会始终运行 不会被主线程上的活动(如用户点击按钮 提交表单)打断 这样有利于随时响应主线程的通信
    2. 这也造成Worker比较耗费资源 不应过度使用 而一旦使用完毕 就应该关闭

    > 使用注意点
    > (同源限制/DOM限制/通信联系/脚本限制/文件限制)
    1. 同源限制
        - 分配给Worker线程运行的脚本文件 必须与主线程的脚本文件同源
    2. DOM限制
        - Worker 线程所在的全局对象，与主线程不一样，无法读取主线程所在网页的 DOM 对象，也无法使用document、window、parent这些对象。但是，Worker 线程可以navigator对象和location对象。
    3. 通信联系
        - Worker 线程和主线程不在同一个上下文环境，它们不能直接通信，必须通过消息完成。
    4. 脚本限制
        - Worker 线程不能执行alert()方法和confirm()方法，但可以使用 XMLHttpRequest 对象发出 AJAX 请求。
    5. 文件限制
        - Worker 线程无法读取本地文件，即不能打开本机的文件系统（file://），它所加载的脚本，必须来自网络。
    > 基本用法:
    > 主线程
    1. 主线程采用new命令，调用Worker()构造函数，新建一个 Worker 线程。
    var worker = new Worker('work.js');
    Worker()构造函数的参数是一个脚本文件，该文件就是 Worker 线程所要执行的任务。由于 Worker 不能读取本地文件，所以这个脚本必须来自网络。如果下载没有成功（比如404错误），Worker 就会默默地失败。
    2. 然后，主线程调用worker.postMessage()方法，向 Worker 发消息。worker.postMessage()方法的参数，就是主线程传给 Worker 的数据。它可以是各种数据类型，包括二进制数据。
    3. 主线程通过worker.onmessage指定监听函数，接收子线程发回来的消息。
    。。。
31. HTTP报文头部字段
    - HTTP协议的请求和响应报文中必定包含HTTP首部
    - 首部内容为客户端和服务器分别处理请求和响应提供所需的信息
    - 请求和响应中都会存在首部字段 它们为浏览器和服务器 
    传递额外重要信息 通常HTTP首部字段由首部字段名和字段值 
    中间以:分割
    如 Request Method:GET
    字段值对应单个HTTP首部字段可以有多个值
     cache-control:public,max-age=0
    首部字段类型
    (据实际用途分为四种类型)
    通用首部字段:
    请求报文和响应报文两方都会使用到的首部
    Cache-Control 控制缓存行为
    Connection  逐跳首部 连接的管理
    Date    创建报文的日期时间
    Pragma  报文指令
    Transfer-Encoding   指定报文传输主体的编码方式
    Upgrade 升级为其他协议
    Via     代理服务器的相关信息
    Warning   错误通知   

    请求首部字段:
    客户端向服务端发送请求时使用
    补充请求附加内容 客户端信息 响应内容等优先级信息
    Accept  用户代理可以处理的媒体类型
    Accept-Charset  优先的字符集
    Accept-Encoding 优先的内容编码
    Authorization   Web认证信息
    Except  期待服务器的特定行为
    Host    请求资源所在服务器
    if-Match    比较实体标记 ETag
    if-Modified-Since 比较资源的更新时间
    Range 实体的字节范围请求
    Refer 实体的字节范围请求
    TE  传输编码的优先级
    User-Agent HTTP客户端程序的信息

    响应首部字段:
    服务端向客户端返回响应报文使用
    补充响应时的附加内容 也会要求客户端附加额外的内容信息
    Accept-Ranges 是否接受字节范围请求
    Age 推算资源创建经过的时间
    ETag 资源的匹配信息
    Location    令客户端重定向至指定UPI
    Proxy-Authenticate 代理服务器对客户端的认证信息
    WWW-Authenticate 服务器对客户端的认证信息
    Server HTTP服务器的安装信息
    Vary    代理服务器的管理信息

    实体首部字段:
    针对请求报文和响应报文的实体部分使用到了的
        通用头部字段
        Cache-Control
            缓存
        Connection:close/keep-alive
        Transfer-Encoding 报文传输过程中采用的编码格式
        Via 追踪请求和响应报文测传输路径
        请求头部字段
        Accept 通知服务器用户代理能处理的媒体类型及该媒体类型对应的优先级
        Accept-Encoding 告知服务器，客户端这边可支持的内容编码以及相应内容编码的优先级, 下方就是Accept-Encoding的用法
        Accept-Language 告知服务器，客户端可处理的自然语言集，以及对应语言集的优先级。
        User-Agent:Wget/1.12(linux-gnu)
            表示客户端使用的程序是Wget
        Authorization
            告知服务器用户端的认证信息，下方就是连接公司内部SVN系统时需要认证时的请求头部信息。
        If-Match 与If-None-Match
    If-Modified-Since与If-Unmodified-Since
        User-Agent

        Host:www.baidu.com
            表示目标主机 HTTP请求中必须包含的头部字段



