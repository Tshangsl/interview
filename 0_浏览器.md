1. 浏览器是如何工作的
    > 浏览器输入url后发生了什么
    - (
        1. DNS解析 将我们输入在地址栏中的URL通过DNS解析成IP地址
        2. TCP连接(传输层)
        3. HTTP请求(应用层)
        > 以下实际进行时不是独立的会有交叉
        4. 构建DOM树
        5. 构建CSSOM树
        6. 构建Render树
        7. 布局Layout
        > 回流:据render渲染树 计算哪些节点 各节点CSS及从属关系
        > 重绘:据render渲染树及回流得到的节点信息 计算每个节点屏幕中位置
        > 绘制Painting(浏览器图形处理程序)
    )
    1. DNS解析
        > (将我们输入在网页地址栏的URL通过DNS解析成IP地址)
        > (查找是否存在该域名对应的IP地址 
        > 系统(浏览器/操作系统)缓存查询=>(向DNS服务器发送请求)路由器缓存/ISP缓存=>DNS递归/迭代查询)
        1. 为什么进行DNS解析
            > 要想得到接收方的MAC地址 需要通过对方的IP地址获取 对方的IP需要通过DNS解析
            - DNS解析：
            > 将我们输入在网页地址栏的URL通过DNS解析成IP地址
            - DNS：
            > 将域名转化为IP地址的过程
            - DNS解析过程中发生什么
            > (系统(浏览器/操作系统)=>(向DNS服务器发送请求)路由=>ISP缓存查询=>DNS递归迭代查询)
        2. 系统缓存查询
            >(系统缓存中查找是否存在该域名对应的IP地址)
            1. 浏览器会调用一个库函数 检测本地的hosts文件(可以认为是电脑本地的一个地址映射文件) 从该文件中查看是否有对应的该域名的IP地址
        3. 路由器缓存 ISP缓存
            1. 如果系统缓存没有 就会向DNS服务器发送请求 而网络服务一般都会先经过路由器以及网络服务商(电信)所以会先查询路由器缓存 然后再查询ISP的DNS缓存
            2. ISP缓存 本身是一种宽带接入提供商给网页批量访问加速的技术
            >ISP会将当前访问量较大的网页内容放到ISP服务器缓存中 
            >当有新的用户请求相同内容的时 可以直接从缓存中发送相关信息 而不必每次都去访问真正的网站 从而加快不同用户对相同内容的访问速度 同时也能节省网间流量结算成本
        4. DNS递归查询
            > 如果路由缓存和ISP缓存的DNS缓存还是没有的话 我们就进行DNS递归查询
            > 从根域名服务器开始查询 然后再到顶级域名服务器 再到主域名服务器依次查询
            > 两种查询方式
            1. 递归查询(服务器端递归查询 返回给客户端查询结果)
                > DNS服务器收到请求时 检查DNS缓存 
                > 如果没有就会询问其他服务器 并将返回的查询结果返回给客户端
            2. 迭代查询(服务器端返回客户端另一台服务器地址 客户端向另一台服务器发起请求)
                > DNS收到请求时 不是直接返回查询结果 而是告诉客户端另一台DNS服务器地址 
                > 然后客户端再向这台DNS服务器提交请求 依次循环
        5. DNS优化(浏览器缓存/DNS负载均衡)
            1. 浏览器缓存 本地的DNS缓存服务器
            2. DNS负载均衡 DNS根据每台机器的负载量 地理位置的限制等 去提供高效快速的DNS解析服务
    2. TCP连接
        >通过DNS查询到IP地址后 下一步与服务器建立联系 为下面的数据传输做准备
        1. TCP
            > (Transmission Control Protocol传输控制协议)
            一种面向连接的 可靠的 基于字节流的传输层通信协议
        2. TCP头部报文
            1. 源端口号(source port)目的端口号(destination port)
                socket(套接字):
                应用程序的端口号和
                应用程序所在的主机的IP地址
                互联网中socket唯一标识每一个应用程序
                套接字对 源端口+源IP+目的端口号+目的IP
                (一对套接字对就是一个连接)                    
            2. 序列号(Sequence Number)
                (确保数字通信有序性 
                保证分割数据段在原始数据包位置 
                初始序列号由自己决定 
                后续由对端ACK决定)
            3. TCP flag
                > TCP首部有六个标志比特 它们中的多个可同时被设置为1 依次为URG ACK PSH RST SYN FIN
                1. ACK
                    应答域有效 有两个取值 0 1
                        1 应答域有效 0 无效
                2. SYN 同步序列号
                (这个标志位的数据包长用来进行端口扫描)
                    TCP握手发送的第一个数据包 用来建立TCP连接
                    SYN标志位和ACK标志位搭配使用 
                    连接请求时：SYN=1 ACK=0
                    连接被响应时：SYN=1 ACK=1
                        
                    扫描者发送一个只有SYN的数据包 如果对方主机响应了一个数据包回来
                    表明这台主机存在这个端口
                3. FIN
                    表示发送端已经达到数据末尾 
                    发送FIN标志位的TCP数据包后 
                    连接将被断开
                4. URG
                5. RSG
                6. PSH
            4. Window Size   
                滑动窗口的大小 用来进行流量控制
        3. 为什么进行TCP三次握手：
        > (确认双方接收发送数据能力/
        > 指定自己初始化序列号 为后面可靠传输做准备/
        > HTTPS协议三次握手 会进行CA证书的验证 以及加密密匙的生成)
        4. TCP三次握手过程：
            >最重要两点：
            > (客户端服务器端状态变化/标志信息变化)
            - 客户端和服务器端状态的变化
                (Client Server
                closed listen
                SYN_Send Listen
                SYN_Send SYN_Recieve
                Established SYN_Recieve)
            - 三次握手过程标志信息的变化
            (SYN(Client)=1(j)
                SYN(Server)=0(k) ACK(1)=SYN(Client)+1(ACK)=1
                ACK=SYN(Server)+1(ACK=1)
            )
            1. 初始状态：
                1. 客户端处于closed(关闭)状态
                2. 服务器处于listen(监听)状态
            2. 第一次握手(SYN=1(j) 客户端SYN_Send状态)
                客户端发送请求报文 将SYN=1(j)初始化序列发送给客户端
                发送完后 客户端将处于SYN_Send状态
            3. 第二次握手(SYN)
                服务端收到SYN请求报文后 如果同意连接 
                会以自己的SYN(服务端) = 0(K)
                和ack(1) = SYN(客户端)+1(ACK=1)报文作为答应
                服务器为SYN_Recieve状态
            4. 第三次握手
                客户端收到服务端的SYN+ACK然后发送ACK = SYN(服务端)+1(ACK=1)
                确认包作为应答 客户端转为established状态
            5. 为什么不是一次两次握手
                1. 防止服务器端一直等待浪费资源
                2. 防止已经失效的 连接请求报文段 突然传送到服务端 因而产生错误
    3. HTTP请求
        客户端与服务器端通过TCP三次握手建立连接后 
        客户端开始向服务端主动发起请求
        服务器端接收到客户端发送的信息 
        返回响应文件和信息 状态码
        浏览器的渲染原型
    四次挥手释放TCP连接
    4. 构建DOM树
    5. 构建CSSOM树
    6. 生成渲染树
    7. 合成绘制
2. 浏览器渲染引擎工作流程
    1. 解析HTML生成DOM树 解析CSS 生成CSSOM树 将DOM树和CSSOM树结合生成渲染树 render
    2. 根据渲染树 浏览器计算出页面有哪些节点 各节点的CSS以及从属关系-回流 
    3. 根据渲染树以及回流得到的节点信息 计算出每个节点在屏幕中的位置-重绘 
    4. 最后将得到的节点位置信息交给浏览器的图形处理程序 让浏览器显示页面

    (以上流程不一定会严格遵守先后顺序 有可能同时出现)
    1. 创建DOM树 HTML分析器 分析HTML元素 构建一棵DOM树
    2. 创建StyleRules CSS分析器 分析CSS文件 构建Rules树 生成CSSOM树
    3. 创建Render树 将DOM树和Rules树关联起来 构建一颗Render树
    4. 布局Layout分析布局信息 计算坐标位置
    5. 绘制Painting 开始绘制
3. 重绘(Repaint)重排/回流(Reflow)是什么以及如何减少重绘、避免重排
    - 重排(Reflow)/回流/重构
        DOM中各个元素都有自己的盒子模型，
        需要浏览器根据样式进行计算，
        并根据计算结果将元素放到特定位置，
        这就是Reflow

        当渲染树中的一部分(或全部)因为元素的规模尺寸，布局，隐藏等改变而需要重新构建，这就是回流
        每个页面至少需要回流一次，就是在页面加载的时候
    - 触发Reflow条件
        (任何页面布局和几何属性的改变都会触发回流)
        1. 增、删、改、移DOM
        2. 修改CSS样式
        3. Resize窗口
        4. 页面滚动
        5. 修改网页的默认字体
        1.布局流相关操作
            1.盒模型相关操作
            2.定位相关操作
            3.浮动相关操作
        2.改变节点内的内容
        3.CSS
    - 重绘（Repaint)
        当节点的部分属性发生变化 但不影响布局，只需要重新计算节点在屏幕中的绝对位置并渲染的过程，就叫重绘。
        1. 当各种盒子的位置、大小以及其他属性改变时，
        2. 浏览器需要把这些元素都按照各自的特性绘制一遍，
        3. 这个过程称为Repaint。
        table(渲染树中节点的属性值)
        table及其内部元素可能需要多次计算才能确定好其在 
        渲染树中节点的属性值，
        比同等元素要多花两倍时间
        这就是我们尽量避免使用table布局页面的原因之一
    - 触发Repaint的条件：
        DOM改动
        CSS改动
    - 重绘和回流：
        在回流的时候，浏览器会使渲染树中受到影响的部分失效，并重新构造这部分渲染树，完成回流后，浏览器会重新绘制受影响的部分到屏幕中，该过程称为重绘
        回流一定会引发重绘 重绘不一定会引发回流
    - 重绘重排的代价：
        耗时 导致浏览器卡慢
    - 减少重绘、避免重排
        本质上，就是合并修改
        具体的措施有：
            DOM层面：
                将需要变动的DOM节点先汇总到DocumentFragment
                然后一次性插入 减少DOM操作次数
                DocumentFragment本质上是一个占位符，真正插入页面的是它的所有子孙节点
            CSS层面：
                操作多个样式 汇总到一个类中 然后一次性修改
                减少对style样式的请求
        DocumentFragment
            文档片段接口 一个没有父对象的最小文档对象
            它被作为一个轻量级的Document使用 就像标准的document一样 存储由节点nodes组成的文档结构
            与document相比 最大的区别是DocumentFragment不是真实DOM树的一部分 它的变化不会触发DOM树的重新渲染 且不会导致性能等问题
    - 优化：
        1.每次回流都会对浏览器造成额外的计算消耗，所以浏览器对于回流和重绘有一定的优化机制。
            浏览器通常都会将多次回流操作放入一个队列中，等过了一段时间或操作达到了一定的临界值，然后才会挨个执行，这样能节省一些计算消耗。
            但是在获取布局信息操作的时候，会强制将队列清空，也就是强制回流，比如访问或操作以下或方法时：
        2.操作时做的优化，减少对渲染树的操作，合并多次的DOM和样式修改，并减少对style样式的请求
4. window.onload window.open
    - window.onload
        网页加载完毕后立即执行的操作
        即当HTML加载完毕后 立即执行某个方法等
        因为页面中的代码一般情况下 从上到下 从左到右顺序执行
        所以当JS代码需要获取页面中的元素时
        如果script标签在元素前面 需要加window.onload
        如果script标签在元素后面 不需要加window.onload
    - window.open
        用于打开一个新的浏览器窗口或查找一个已命名的窗口
        语法 window.open(URL,name,space,replace)
5. window对象 document对象
    - window
        JS中最大的对象
        表示窗口
        包含document
    - document
        文档对象
        表示HTML
6. 浏览器线程
    1. JS引擎线程(解释执行JS代码 用户输入 网络请求)
    2. GUI线程(绘制用户界面 与JS主线程是互斥的)
    3. HTTP网络请求线程(处理用户的get/post等请求 等返回结果后将回调函数推入任务队列中)
    4. 定时触发器线程(setTimeout setInterval等待时间结束后把执行函数推入任务队列中)
    5. 浏览器中事件处理线程(将click mouse 等交互事件发生后 将这些事件放入事件队列中)
7. HTTP缓存和CDN缓存
    > HTTP缓存
    - 客户端缓存 浏览器作为客户端收到服务器端响应后 对响应首部字段进行解析 分析出相应的缓存规则 将资源按规则进行缓存 再次请求时 如果命中缓存 则直接读取本地缓存 不再发出请求
    - 缓存规则
        > HTTP缓存规则由响应首部字段控制
        关键字
        > (确定缓存存储时间 1.0Expires 1.1Cache-Control)
        > (确定缓存是否需要被更新/缓存对比 Last-Modified Etag)
        1. 确定缓存存储时间
            > Expires
            - HTTP1.0中用来控制缓存时间的参数 响应头包含日期/时间 在此时间后 响应过期 过去的时间或无效时间 缓存但立即过期 等同于cache-control = no-cache ß未来的时间 缓存到对应时间 
            > Cache-Control
            - (public/private/max-age/s-max-age/no-store/no-cache)
                > HTTP1.1中用来控制缓存的参数
                1. public:表示响应可以被任何对象(包括：发送请求的客户端 代理服务器 等等)缓存
                2. private:表示响应只能被单个用户缓存 不能用作共享缓存(即代理服务器不能缓存它)
                3. max-age=<seconds>:设置缓存存储最大周期相对请求时间缓存seconds秒 在此期间 访问资源直接读取本地缓存 不向服务器发起请求 (与expires同时出现 max-age优先级更高)
                4. s-max-age=<seconds>: 规则等同max-age 覆盖max-age/Expires头 但是仅适用于共享缓存(如各个代理)并且私有缓存中它被忽略(于expires/max-age同时出现 s-maxage优先级更高)
                5. no-store:不缓存服务器相应的任何内容 每次访问资源都要服务器完整响应
                6. no-cache:缓存资源 但立即过期 每次请求都要跟服务器对比验证资源是否被修改(等同max-age=0)
        2. 确定缓存是否要被更新(缓存对比)
            > Last-Modified
            > Last-Modified对应If-Modified-Since
            > (上次修改时间 缓存过期 与请求中If-Modified-Since比对 一致则继续使用之前缓存 不一致则认为失效)
            > (包含If-Modified-Since&If-Unmodified-Since)
            - 源头服务器认定的资源做出的修改的日期及时间 上次修改时间 如果缓存时间过期 该字段将用于 与请求中if-Modified-Since对比 一致则继续使用之前的缓存 不一致则认为缓存失效 精度比Etag低
                包含
                if-Modified-Since
                if-Unmodified-Since
                首部的条件请求会使用这个字段
            > Etag(服务端的一个资源的标识)
            > 查询服务器端资源是否更新 优先对比Etag 
            > Etag对应If-None-Match 再用对比Last-ModifiedLast-Modified对应If-Modified-Since
            - Entity缩写 可理解为被请求变量的实体值 是服务器的一个资源标识 在HTTP响应头中将其传送给客户端 服务器端资源可以是一个Web页面 JSON/XML 服务器单独负责判断记号是什么及其含义 并在HTTP响应头中将其传送到客户端 HTTP响应头是资源的特定版本的标识符
            - 分布式系统尽量关闭Etag 因为每台机器生成的Etag都不一样 分布式系统多台服务器间文件的If-Modified-Since必须一致 避免负载均衡不同导致对比失败
            > 资源的内容标识(不唯一 通常为文件的md5或者一段hash值 只要保证写入和验证时的方法一致即可)
                If-None-Match：
                    客户端保留的资源内容标识
            > 注意:
            1. 分布式系统尽量关闭Etag 因为每台机器生成的Etag都不一样
            2. 分布式系统里多台机器间文件的Last-Modified必须一致 避免负荷均衡不同导致对比失败
            3. 通常情况下 如果同时发送if-None-Match If-Modified-Since字段 服务器只要比较Etage的内容即可 当然具体的处理方式 看服务器的约定规则
        3. 缓存流程中三个问题
            1. 缓存是否过期
                > 基于该资源上次响应缓存规则 同时满足下列条件 则视为缓存未过期 
                > 判断缓存是否过期只跟客户端相关 与服务端无关 
                > 1&2&3同时满足即认为缓存未过期 相反过期
                1. cache-control值为max-age
                2. max-age>0
                3. 当前data<上次请求时date+max-age
                > PS:expire可同等转化为cache-control=max-age形式 s-maxage与maxage规则相同
            2. 询问服务器资源是否修改
                >(Etag对应If-None-Match 优先对比Last-Modified对应If-Modified-Since) 判断资源是否修改 需要客户端与服务器共同协作 客户端在首次拿到资源缓存后会存储Etag(若有)和Last-Modified(若有) 
                在下次缓存过期时 
                会将Etag写在请求头部中的If-None-Match中
                将Last-Modified值写在请求头部中的If-Modified-Since中 
                服务端优先对Etage进行对比
                一致情况下才会继续对比Last-Modified 
                完全通过后即视为缓存没有修改
                决定返回304 
                告诉浏览器资源未更新 可以使用本地缓存
                有一项不通过则认为资源已被修改 缓存失效
            3. 缓存规则
                > 缓存规则主要由cache-control字段和expires字段体现 同时出现则以cache-control为准
            > 总结:
            >对于HTTP缓存的配置 始终要做到两点
            1. 清楚明白HTTP缓存的原理与规则
            2. 明确缓存的配置不是一次性的
    > CDN缓存(Content Delivery Network)内容分发网络
        > (缓解源站压力 优化不同用户的访问速度和体验)
        > CDN缓存是一种服务端缓存 
        > CDN服务商将源站的资源缓存到遍布全国的高性能加速节点上 当用户访问相应的业务资源时 用户会被调度至最接近的节点 最近的节点ip返回给用户 
        > web性能优化中 它主要起到了 缓解源站压力 优化不同用户的访问速度和体验的作用
        > 缓存规则：(由CDN服务商制定) 与HTTP缓存不同的是 这个规则不是规范性的 而是有CDN服务商来制定
        > 关于CDN缓存,在浏览器本地缓存失效后,浏览器会向CDN边缘节点发起请求。类似浏览器缓存,CDN边缘节点也存在着一套缓存机制。CDN边缘节点缓存策略因服务商不同而不同，但一般都会遵循http标准协议，通过http响应头中的
        > Cache-control: max-age 
        > 字段来设置CDN边缘节点数据缓存时间。当浏览器向CDN节点请求数据时，CDN节点会判断缓存数据是否过期，若缓存数据并没有过期，则直接将缓存数据返回给客户端
        > 否则，CDN节点就会向服务器发出回源请求，从服务器拉取最新数据，更新本地缓存，并将最新数据返回给客户端。 CDN服务商一般会提供基于文件后缀、目录多个维度来指定CDN缓存时间，为用户提供更精细化的缓存管理。
    > CDN优势:
    1. CDN节点解决了跨运营商和跨地域访问的问题，访问延时大大降低。
    2. 大部分请求在CDN边缘节点完成，CDN起到了分流作用，减轻了源服务器的负载。
    > 总结：
        CDN缓存的配置并不复杂 
        复杂的情况在于CDN缓存配置会受到HTTP缓存配置的影响 并且不同的CDN运营商对于这种影响的处理也都不一致
        实际使用时 建议去对应的CDN服务商文档中找到对应的注意事项
    > HTTP缓存和CDN缓存结合  
        > HTTP缓存和CDN缓存分别作为客户端缓存和服务端缓存共同影响着我们的web请求流向 想做好缓存配置 首先清楚缓存的原理和配置规则 其实是结合项目分析缓存级别 具体情况具体处理
    > DNS缓存 查询过程
    1. 首先搜索浏览器自身的DNS缓存,如果存在，则域名解析到此完成。
    2. 如果浏览器自身的缓存里面没有找到对应的条目，那么会尝试读取操作系统的hosts文件看是否存在对应的映射关系,如果存在，则域名解析到此完成。
    3. 如果本地hosts文件不存在映射关系，则查找本地DNS服务器(ISP服务器,或者自己手动设置的DNS服务器),如果存在,域名到此解析完成。
    4. 如果本地DNS服务器还没找到的话,它就会向根服务器发出请求,进行递归查询。
7. 浏览器缓存
    > 定义
        > 浏览器将用户请求过的静态资源（html、css、js 存储到电脑本地磁盘中
        > 浏览器再次访问时 可以直接从本地加载了 不需再去服务端请求
    > 浏览器打开一个页面前端缓存 一般针对如CSS JS image等静态资源
    > 缓存缺点
        > 如果处理不当，可能会导致服务端代码更新了，但是用户却还是老页面。
        所以前端们要针对项目中各个资源的实际情况，做出合理的缓存策略。
    > 缓存的优点：
    1. 减少了冗余的数据传输，节省网费
    2. 减少服务器的负担，提升网站性能
    3. 加快了客户端加载网页的速度
8. 前端清除缓存几种方法
    > (meta标签清理缓存/
    随机数 随机时间/
    Jquery AJAX清除浏览器缓存/
    php后端处理)
    1. meta标签清理缓存 
    <meta http-equiv="Pragma" content="no-cache">
    用于设定禁止浏览器从本地机的缓存中调阅页面内容
    有时谷歌等浏览器不支持
    <meta http-equiv="Cache-Control" content="no-cache">
    Cache-Control指定请求和响应遵循的缓存机制。在请求消息或响应消息中设置Cache-Control并不会修改另一个消息处理过程中的缓存处理过程
    <meta http-equiv="Expires" content="0">
    可以用于设定网页的到期时间
    2. jquery ajax清除浏览器缓存
        1. 用AJAX请求服务器最新文件 并加上请求头if-Modified-Since和Cache-Control
        2. 直接用cache:false
    3. 随机数
        url参数后面加上"?ran="+Math.random()
    4. 随机时间 和随机数一样
        url参数后面加上"?timestamp="+new Date().getTime();
    5. php后端处理
        在url参数后加上 在服务器端加
        header("Cache-Control:no-cache,must-revalidate")
9. 前端优化网站性能/前端浏览器性能优化
    > (减少HTTP请求数量/
    利用浏览器缓存/
    控制资源文件加载优先级/
    减少重排/减少DOM操作
    图标从字体图标改为图片图标
    尽量外链JS CSS)
    1. 减少 HTTP 请求数量 CSS Sprites 采用 lazyLoad
    2. 利用浏览器缓存 
    3. 控制资源文件加载优先级 浏览器加载HTML内容时 将HTML内容从上至下依次解析 解析到link/script标签会加载href/src对应链接内容 为第一时间展示页面给用户 需要将CSS提前加载 不要受JS加载影响 一般情况下都是CSS在头部 JS在尾部
    4. 减少DOM操作 减少重排（Reflow）避免重排
    5. 尽量外链CSS和JS(结构/表现/行为分离)
    6. 图标由字体图标改成图片图标
10. 前端首屏优化
    > (CDN分发 减少传输距离/
    后端在业务层的缓存/
    静态文件缓存方案/
    前端资源动态加载/
    减少请求数量/
    页面使用骨架屏/
    使用SSR渲染/
    引入HTTP2.0/
    利用好HTTP压缩/
    利用好script标签的defer和async两个属性)
    1. CDN分发(减少传输距离)
        > 在多台服务器部署相同的副本 用户访问时 服务器根据用户与那台服务器距离近 决定那台服务器去响应这个请求
    2. 后端在业务层的缓存(数据库查询可设置缓存)
        > 数据库查询缓存可设置缓存 此对处于高频率的请求很有用 浏览器一般不会对content-type:application/json; 的接口进行缓存 所以有时需要手动为接口设置缓存 比如一个用户的签到状态 它的缓存时间可以设置到明天之前
    3. 静态文件缓存方案
        > 最常看到 最流行的方式是hash+强缓存方案 如hash+cache control:max-age=1年
    4. 前端资源动态加载
        1. 路由动态加载 最常用的方法 以页面为单位 进行动态加载
        2. 组件动态加载 对于不在当前视窗的组件 先不加载
        3. 图片懒加载 同上 越来越多的浏览器支持原生的懒加载 通过给img标签加上loading='lazy'来开启懒加载模式
    5. 减少请求的数量
        > 该点在HTTP1.1优势很明显 因为HTTP1.1的请求是串行的 (尽管有多个TCP通道) 每个请求都需要往返后才能继续下个请求
        此时合并请求可以减少在路途上浪费的时间 此外还会带来重复的请求头部信息(比如cookie)
        > HTTP2.0 新的二进制格式 多路复用 header压缩 服务器端推送 中该问题会弱化很多 但是也有做的必要
    6. 页面使用骨架屏 
        > 即为在首屏加载完成之前 通过渲染一些简单元素进行占位 骨架屏好处在于可以减少用户的等待时的急躁情绪  这点很有效 在很多成熟的网站(京东 淘宝 Youtube)都有大量应用 没有骨架屏的话 一个loadingdd的菊花图也是可以的
    7. 使用SSR渲染
    8. 引入HTTP2.0 HTTP2.0相对于HTTP1.1 最主要提升是传输性能 在接口小而多时会更加明显
    9. 利用好HTTP压缩
        > 即使是最普通的gzip 也能把bootstrap.min.css压缩到原来的17% 压缩的效果非常明显 特别是对文本类的静态资源 
        > 此外 接口也是能压缩的 接口不大不用压缩 因为性价比低(考虑压缩和解压时间)
    10. 利用好script标签的async和defer这两个属性
        > 功能独立且不要求马上执行的JS文件 可以加入async属性
        > 优先级低且没有依赖的JS 可以加入defer属性
11. 浏览器内核
    > 浏览器内核
        > (浏览器内核不同 对网页的语法解释不同 渲染效果不同)
        > (所有网页浏览器 电子邮件客户端及其他需要编辑 显示网络内容的应用程序都需内核)
        > 渲染引擎Layout Engineer/Rendering Engine
            取得网页的内容(HTML/XML/图像等)
            整理讯息(如加入CSS)
            计算网页显示方式
            输出至显示器/打印机
        > JS引擎
            解析执行JS实现网页动态效果
    常见的浏览器内核
        Trident:IE 360 搜狗
        Gecko:FireFox Netscape6及以上版本
        Presto:Opera
        Blink:Opera Google
        Webkit:Safari Chrome
    最开始渲染引擎和JS引擎没有区分很明确
    后来JS引擎越来越独立 内核就倾向于只指渲染引擎

    -webkit- 针对safari chrome浏览器的内核css写法
    -moz- 针对firefox浏览器的内核css写法
    -ms- 针对IE内核的css写法
    -o- 针对Opera内核的css写法
12. 如何避免页面上商品价格被爬取到
    1. 价格信息AJAX获取
    2. 价格设置图片
    3. JS对价格加密再解密
    4. 字体加密 如#xf076对应100
13. 前端常用的几种弹窗函数
    (alert/confirm/prompt/HTML+CSS+JS)
    1. alert('')弹窗 提示
        主要作为提示
        一般经常用来测试JS某段代码是否出错
    2. confirm('')弹窗 判断是否进行某一个操作
        点击确定 返回true
        点击取消 返回false
        点击确定/取消按钮关闭前 将阻止用户对浏览器的所有输入       
    3. prompt('')弹窗 用于输入文本内容 
        用于显示可提示用户进行输入的对话框
        用户单击取消按钮 返回null
        单击确认按钮 返回输入的文本
        点击确定或取消关闭之前
        它将阻止用户对浏览器的所有输入
        调用prompt()时 用户做出响应之前 不会执行下一条语句
    4. HTML+CSS+JS实现浏览器弹窗
        click控制div.style.display为block/none        
14. 前端文件上传功能
    > (form表单/原生JS+AJAX/Jquery+AJAX/formdata+iframe)
    > Web浏览器上传文件一般有以下几种方式
    1. form表单上传文件
        > 会整个刷新页面 浏览器支持 不使用JS也可以实现
    2. 原生js实现ajax上传文件
        > 基于JS实现 通过formdata对象实现 formdata对象在老版本浏览器中不支持 不会刷新整个页面
    3. jquery实现ajax上传文件
        > 基于JS实现 formdata对象在老版本浏览器中不支持 不会刷新整个页面
    4. form+iframe上传文件
        > 使用iframe方式提交 兼容老版本浏览器
15. Web标准及W3C理解认识
    > Web标准简单来说可以分为
    - 结构：主要由HTML标签组成
    - 表现：CSS样式表
    - 行为: 页面和用户交互
    > Web标准一般将该三部分独立分开 使其更具有模块化
    > 一般产生行为时 会有结构或表现的变化 使该三者界限不够清晰
    > W3C对Web标准提出规范化要求 即实际编码中一些代码规范
    1. 结构要求
        (标签规范可以提高搜索引擎对页面的抓取效率 对SEO较有帮助)
        1. 标签字母小写
        2. 标签闭合
        3. 标签不允许随意嵌套
    2. CSS/JS
        1. 尽量使用外链CSS样式表和JS脚本 使结构表现行为分三块 符合规范 同时提高页面渲染速度 提高用户体验
        2. 样式尽量少使用行内样式 使结构和表现分离 标签的id和class等属性命名要做到见文知义，标签越少，加载越快，用户体验提高，代码维护简单，便于改版
        3. 不需要变动页面内容，便可提供打印版本而不需要复制内容，提高网站易用性。
16. 负载均衡(流量分发 提高性能和可用性 消除单点障碍)
    > 高可用架构的一个关键组件 主要用来提高性能和可用性 通过负载均衡将流量分发到多个服务器 同时多个服务器能够消除这部分的单点故障
    > 负载均衡可以处理那些类型的流量
    > (HTTP HTTPS流量 TCP/UDP流量 数据库集群访问 DNS)
    1. 一般接触到的负载均衡可能大多是处理HTTP HTTPS流量
    2. 实际上负载均衡还可以处理TCP/UDP流量
    3. 如对数据库集群的访问 DNS等
    > 负载均衡算法(确定流量应该被分发到哪一个健康的服务器上)
    > 用途：用于确定流量应该被分发到哪一个健康的服务器上
    > 常见的几个：(轮转/最少连接/IP hash)
    1. Round Robin 轮转
        > 服务器按顺序选择 比较适合各服务器处理能力相同且每个业务处理量差不多的时候  
    2. Least Connections 最少连接
        >  负载均衡器会选择当前连接最少的服务器
    3. IP hash
        > 负载均衡器根据请求源的IP决定分发给哪个服务器 该方法保证一个特定用户会一直访问相同的服务器
    4. Url Hash Random等
    
    > 健康检测
    > 负载均衡算法有一个前提 流量只会被分配到健康的服务器上 一般会通过配置的协议和端口尝试连接服务器保证服务器正在监听 如果一个服务器的健康检查失败 即服务器无法正常响应请求 那么就会被自动移除池子中 流量也不会被分配到这个坏掉的服务器 直到它能通过健康检查
    
    > 负载均衡处理状态
    > session用户认证 在服务器集群下 不能轻易做到状态共享
    > 解决方法(IP hash/sticky session)
    1. IP hash算法
    2. sticky session 粘性会话
        > 负载均衡器会设置一个cookie 然后带有这个cookie的session都会被分配到同一个服务器上
    
    > 负载均衡双机热备 Hot standby
        > 负载均衡器本身就是一个单点故障隐患
        > 其中一个解决方案
        > 双机热备(提高可用性的一大基本方法就是冗余)
            > 为解决负载均衡器的单点故障问题 引入第二个负载均衡器 主节点故障则切换到备用节点
17. SEO/前端SEO优化
    > (蜘蛛是否能看懂/网页内容是否能被搜索引擎识别
    > 网页内容可以被搜索引擎识别 搜索引擎会提高该网站的权重
    > 增加对该网站的友好度 --SEO)
    > (白帽SEO/黑帽SEO)
    > (提高网站权重/增强搜索引擎友好度)
    > (网站结构布局尽量扁平化/网页代码优化/前端性能优化)
    1. 搜索引擎工作原理
    > (搜索引擎后台有一个非常庞大的数据库 存储海量关键字 每个关键字对应很多网址 搜索引擎蜘蛛/网络爬虫 爬取而来 一个关键字对应多个网址 即出现排序问题 搜索引擎是否理解该关键字 网站内容是Flash和JS 它无法理解 如网站内容能被搜索引擎识别 搜索引擎提高该网站权重 增加对该网站友好度 此过程即为搜索引擎优化 SEO)
    2. SEO(Search Engine Optimization)/搜索引擎优化 简介
    - SEO与搜索引擎
        > 相互促进 互利共生
    - SEO的存在
        > 为了提升网页在搜索引擎自然搜索结果中的收录数量以及排序位置而做的优化行为。
        > 优化的目的为了提升网站在搜索引擎中的权重，增加对搜索引擎的友好度，使得用户在访问网站时能排在前面。
    - 分类：
        - 白帽SEO
        > 起到了改良和规范网站设计的作用，使网站对搜索引擎和用户更加友好，并且网站也能从搜索引擎中获取合理的流量，这是搜索引擎鼓励和支持的。
        > 作用:
        1. 对网站的标题、关键字、描述精心设置，反映网站的定位，让搜索引擎明白网站是做什么的；
        2. 网站内容优化：内容与关键字的对应，增加关键字的密度；
        3. 在网站上合理设置Robot.txt文件；
        4. 生成针对搜索引擎友好的网站地图；
        5. 增加外部链接，到各个网站上宣传。
        - 黑帽SEO
        > 利用和放大搜索引擎政策缺陷来获取更多用户的访问量，这类行为大多是欺骗搜索引擎 一般搜索引擎公司不支持鼓励
    3. 为什么要做SEO(提高网络权重/增强搜索引擎友好度)
        1. 提高网站的权重，
        2. 增强搜索引擎友好度，以达到提高排名，
        3. 增加流量，改善（潜在）用户体验，促进销售的作用。
    4. 前端SEO规范
        > 前端是构建网站中很重要的一个环节，前端的工作主要是负责页面的HTML+CSS+JS，优化好这几个方面会为SEO工作打好一个坚实的基础。通过网站的结构布局设计和网页代码优化，使前端页面既能让浏览器用户能够看懂（提升用户体验），也能让“蜘蛛”看懂（提高搜索引擎友好度）。
        1. 网站结构布局优化 尽量简单 开门见山 提倡扁平化结构
            1. 控制首页链接数量
            2. 扁平化的目录层次
            3. 导航优化
            4. 网站的结构布局
            5. 利用布局 把重要内容HTML代码放在前面
            6. 控制页面大小 减少HTTP请求 提供网站加载速度
        2. 网页代码优化
            1. 突出重要内容
            2. 语义化书写HTML代码 符合W3C标准 合理使用各种H5标签
            3. a标签：页内链接，要加 “title” 属性加以说明，让访客和 “蜘蛛” 知道。而外部链接，链接到其他网站的，则需要加上 el="nofollow" 属性, 告诉 “蜘蛛” 不要爬，因为一旦“蜘蛛”爬了外部链接之后，就不会再回来了。
            4. 正文标题要用h1标签：h1标签自带权重“蜘蛛” 认为它最重要，一个页面有且最多只能有一个H1标签，放在该页面最重要的标题上面，如首页的logo上可以加H1标签。副标题用h2标签, 而其它地方不应该随便乱用 h 标题标签。
            5. img应使用 "alt" 属性加以说明
            当网络速度很慢，或者图片地址失效的时候，就可以体现出alt属性的作用，他可以让用户在图片没有显示的时候知道这个图片的作用。同时为图片设置高度和宽度，可提高页面的加载速度。
            6. 表格应该使用caption表格标题标签
            caption 元素定义表格标题。caption 标签必须紧随 table 标签之后，您只能对每个表格定义一
            7. br标签：只用于文本内容的换行
        3. 前端网站性能优化
            1. 减少HTTP请求
            2. 控制资源文件加载优先级
            3. 尽量外链CSS和JS（结构、表现和行为的分离）保证网页代码的整洁，也有利于日后维护
            4. 利用浏览器缓存
            5. 减少重排（Reflow）
            6. 减少 DOM 操作
            7. 图标使用IconFont替换
            8. 不使用CSS表达式，会影响效率
            9. 使用CDN网络缓存，加快用户访问速度，减轻服务器压力
            10. 启用GZIP压缩，浏览速度变快，搜索引擎的蜘蛛抓取信息量也会增大
            11. 伪静态设置
18. 浏览器中执行一段JS代码时做了什么
    > JS引擎的内里
    > (JS引擎 JS解释器 V8引擎 Chrome和NodeJS使用引擎 C++辨析)
        > JS引擎 JS解释器
        > V8是JS最受欢迎的引擎之一 
        > 也是Chrome和NodeJS使用的引擎
        > 是用C++编写的
    > JS引擎工作流程
    > (AST Compiler/interpreter Parser解析器/Profiler分析器)
    1. Parser 解析器
    2. AST 抽象语法树
    3. interpreter生成ByteCode 翻译程序生成字节码
    4. Profiler 分析器
    5. Compiler生成优化后的代码
    -  Parser -> AST -> 通过Interpreter/Compiler/JIT生成ByteCode|Profiler查找可优化的代码传递给Compiler
    - Interpreter和Compiler
        > 通常将代码转换为机器可读语言有两种方法
        - Interpreter-解释器 逐行读取代码并立即执行 可以立即开始执行代码 但不会进行优化
        - Compiler-编译器 读取你的整个代码 进行一些优化 生成优化后的代码 虽然需要花费一些时间编译代码 但是会生成对执行时更优的代码
    - JIT(Just In Time) 即时编译 Interpreter Compiler 结合
        > Interpreter和Compiler结合 现在大多数浏览器都在更快 更高效地实现此功能 V8引擎也使用此功能
    - Parser 解析器(可以通过各种JS关键字来识别 区分代码是一个方法还是一个变量)
        > 一种通过各种JS关键字来识别 分析和分类程序各个部分的解析器 
        > 它可以区分代码是一个方法还是一个变量
    - AST 抽象语法树   
        > 基于Parser的分类构造树状结构
        > 可以使用AST Explorer查看该树的结构
        > 词法分析 语法分析
    - ByteCode 字节码
        > 随后将AST提供给Interpreter生成ByteCode
        > Byte不是最底层的代码 但可以执行
        > 此阶段 浏览器借助V8引擎执行ByteCode1进行工作 因此用户无需等待
    - Profiler 分析器(查找可优化的代码)
        > 同时Profier将查找可以被优化的代码 然后将它们传递给Compiler 
        > Compiler生成优化代码的同时 浏览器暂时用ByteCode执行操作 
        > 一旦Comiler生成优化代码 优化代码将完全替换到临时的ByteCode
        > 通过这种方式 可以充分利用Interpreter和Compiler的优点
        - Interpreter执行代码的同时 Profiler寻找被优化的代码 Compiler创建优化的代码 然后将ByteCode码替换成优化后较为底层的代码 例如机器代码
        - 意味着性能将在逐渐提高 同时不会有阻塞执行的时间
    - ByteCode
        > 作为机器代码 ByteCode不能被所有所有计算机理解及执行 它仍然需要像虚拟机或JS V8引擎这样的中间件才能将其转换为机器可读的语言 
        > 这就是为什么我们的浏览可以在上述5个阶段中 借助JS引擎在Interprter中执行ByteCode的原因
    - JS是一门解释型的语言吗(取决于引擎如何实现)
        > JavaScript 是但不完全是一门解释型语言
        > Brendan Eich 最初是在 JavaScript 的早期阶段创建 JavaScript 引擎 “ SpiderMonkey” 的。
        > 该引擎有一个 Interpreter 来告诉浏览器该怎么执行代码。但是现在我们的引擎不仅包括了 Interpreter，还有 Compiler。
        > 我们的代码不仅可以被转换成 ByteCode，还可以被编译输出优化后的代码。因此，从技术上讲，这完全取决于引擎是如何实现的。
    > V8执行一段JS代码过程
    - 站在V8的角度 理解其中的执行机制 能够帮助我们理解很多上层应用 包括Babel Eslint 前端框架的底层机制 
    - JS属于解释型的语言 对解释型语言 解释器会对源代码做如下分析
        1. 通过Parser词法分析和语法分析生成AST
        2. 生成字节码ByteCode
        3. 然后解释器根据字节码执行程序 Profiler寻找优化 传递给Compiler生成优化代码
        
        1. 生成AST
            > 分为两步 
            1. 词法分析(分词 代码分解为token)
                > 分词 将一行行代码分解成一个个token let name = 'sanyuan'; 关键字 变量名 赋值 字符串 解析成四个token
            2. 语法分析(将生成的token数据 按一定语法规则转化为AST)
                > 将生成的这些token数据 根据一定语法规则转化为AST
                > 生成AST后 编译器/解释器后续的工作都要依赖AST而不是源代码
                > babel的工作原理就是将
                1. ES6的代码解析成生成ES6的AST 
                2. 然后将ES6的AST 转换为ES5的AST 
                3. 最后才将ES5的AST转化为具体的ES5代码
                4. 生成AST后 接下来会生成执行上下文
        > babel的工作原理 ES6的代码解析生成ES5的AST ES6的AST转换为ES5的AST ES5的AST转化为具体的ES5代码 生成AST后接下来生成执行上下文
        2. 生成字节码ByteCode
            > 字节码 介于AST和机器码之间的一段代码 但是与特定类型的机器码无关 字节码需要通过解释器将其转换为机器码然后执行
            - 生成AST后 直接通过V8解释器生成字节码
                > 字节码并不能让机器直接运行 (直接转成机器码 体积太大 会引发严重的内存占用问题) 字节码是比机器码轻量得多的代码
                - 字节码仍然需要转换为机器码 但是与原来不同的是 现在不用一次性将全部字节码都转换为机器码 
                - 通过解释器逐行解释字节码 省区生成二进制文件操作 大大降低了内存压力
        3. 执行代码
            > 字节码解释执行的阶段 在执行字节码的过程中，如果发现某一部分代码重复出现，那么 V8 将它记做热点代码(HotSpot)，
            > 然后将这些代码编译成机器码保存起来，这个用来编译的工具就是V8的编译器(也叫做TurboFan) 因此在这样的机制下，代码执行的时间越久，那么执行效率会越来越高 因为有越来越多的字节码被标记为热点代码，遇到它们时直接执行相应的机器码，不用再次将转换为机器码

            > 其实当你听到有人说 JS 就是一门解释器语言的时候，其实这个说法是有问题的。因为字节码不仅配合了解释器，而且还和编译器打交道，所以 JS 并不是完全的解释型语言。
            > 编译器和解释器根本区别在于前者会编译生成二进制文件但后者不会。
            > 这种字节码跟编译器和解释器结合的技术，我们称之为即时编译（JIT）
        > 概括 V8中执行一段JS代码的整个过程
        1. 通过词法分析和语法分析生成AST
        2. 将AST转换为字节码
        3. 由解释器逐行执行字节码 遇到热点代码启动编译器进行编译 生成对应的机器码 以优化执行
19. 关键渲染路径
    > (优化关键渲染路径 优先显示与当前用户操作有关的内容)
    > 性能优化
    > 从收到 HTML、CSS 和 JavaScript 字节到对其进行必需的处理，从而将它们转变成渲染的像素这一过程中有一些中间步骤，优化性能其实就是了解这些步骤中发生了什么，即关键渲染路径。
    > 优化关键渲染路径 优先显示与当前用户操作有关的内容。 
    > 通过优化关键渲染路径，我们可以显著缩短首次渲染页面的时间。 此外，了解关键渲染路径还可以为构建高性能交互式应用打下基础。
    > 优化关键渲染路径
        就是指最大限度缩短执行上述第 1 步至第 5 步耗费的总时间。 这样一来，就能尽快将内容渲染到屏幕上，此外还能缩短首次渲染后屏幕刷新的时间，即为交互式内容实现更高的刷新率。
    > 描述关键渲染路径的词汇
    - 关键资源： 可能阻止网页首次渲染的资源。
    - 关键路径长度： 获取所有关键资源所需的往返次数或总时间。
   -  关键字节： 实现网页首次渲染所需的总字节数，它是所有关键资源传送文件大小的总和。我们包含单个 HTML 页面的第一个示例包含一项关键资源（HTML 文档）；关键路径长度也与 1 次网络往返相等（假设文件较小），而总关键字节数正好是 HTML 文档本身的传送大小。
20. 移动端300ms延迟
    > 原因:
    > 300ms 延迟的由来,是当初07年初苹果发布首款iPhone之前,苹果工程师提出的一个为了优化交互体验的操作.因为当时的网站基本都是为PC等大屏幕设备而写的,而现在需要用小屏幕浏览桌面端网站.当用户用手指把页面放大以后,就有了一个双击缩放(double tap to zoom)的交互.
    > 即在iOS自带的Safari浏览器中快速双击会将网页缩放到原始比例.因此在此浏览器中 用户会有单击或者双击的需求行为 浏览器并不能立刻判断用户是想要单击还是双击 Safari就等待了300ms.看看用户到底想干嘛.鉴于苹果公司这个操作的成功,后续其他的浏览器也因此借鉴了这种行为 
    > 300ms也因此成为了大多数浏览器的一个约定.在当初移动端兴起的时候,300ms是可以让人接受的,但是随着用户对交互体验的要求越来越高,300ms就成为了用户无法忍受的一个点了.
    >解决延迟:
    1. 禁用缩放
    2. 更改默认的视图宽度
    3. css touch-action 不触发默认行为
    4. 引用FastClick库 模拟click 阻止默认click)
        1. 禁用缩放(在meta标签中设置)Chrom和Firefox支持 Safari比较麻烦它有双击缩放和双击滚动等操作
        <meta name="viewport" content="user-scalable=no,initial-scale=1,maximun-scale=1"/>
        > 页面不可缩放 双击缩放功能没有意义 此时浏览器可以禁用默认的双击缩放行为并去掉300ms的点击延迟
        > 缺点:必须完全禁用缩放来达到目的 但是通常情况下 还是希望能通过双指来进行缩放
        2. 更改默认的视口宽度(在meta标签中设置) Chrome和Firefox支持 Safari比较麻烦 它还有双击缩放和双击滚动操作
            <meta name="viewport" content="width=device-width"/>
            如果能识别出一个网站是响应式的网站 那么移动端浏览器就可以自动禁止双击缩放行为 并去掉300ms的点击延迟
            设置上述的meta标签 则浏览器就可以认为网站已经对移动端做过适配优化
        好处:没有完全禁用缩放 而是禁用浏览器默认的双击缩放行为 但用户仍然可以通过双指缩放操作缩放页面
        3. css touch-action IE支持
            touch-action:指定相应的元素上能触发的用户代理(浏览器)的默认行为
            将该属性值设置为touch-action:none 表示该元素上操作不会触发用户代理的任何默认行为 就无需进行300ms的延迟判断了
        4. FastClick专门为解决移动端浏览器300ms点击延迟问题开发的一个轻量级的库 
            原理:在检测到touchend事件时 会用过DOM自定义事件立即发出模拟一个click事件 并把300ms之后发出的click事件阻止掉
            缺点:脚本相对较大 且有时可能会有bug
21. 移动端点击击穿
    > 概念:
        > 页面俩元素A和B,B在A的上面.在B的上面注册了touchstart事件,回调函数中是让B元素隐藏.
        > 当我们点击B元素的时候,除了B被隐藏外,A的click事件也被触发了.这是因为在移动端浏览器中,事件执行顺序是 touchstart => touchmove =>  touchend => click .click是有300ms的延迟.
        > 当B的touchstart事件触发后,B被隐藏了,300ms之后,浏览器触发了click事件,此时的事件已经被派发到了A元素身上.
    > 事件执行顺序 触摸事件 -> 点击事件
    > 移动端的事件是touch事件 也叫触摸事件 因为是用手指触摸的 当然 点击事件还是存在的
    > 移动端浏览器中
    > 事件执行顺序touchstart=>touchmove=>touched=>click
    - touchstart事件:手指触摸屏幕时触发
    - touchmove事件:手指在屏幕上滑动时触发
    - touchend事件:手指离开屏幕时触发
    > click事件是在最后执行的
    > 一般情况下lick是在手指放到屏幕上,并且没有移动过,然后离开,且这个开始触摸到手指离开屏幕的时间较短才能触发
    > 若手指移动了,则不会触发click事件了(看到有的地方说某些浏览器会允许有一个很小的移动值,具体的情况不太清楚).
    > 正确触发顺序是下面两个中一个
    - touchstart=>touchmove=>touchend
    - touchstart=>touchend=>click
        > touchmove可能不会触发 也可能触发很多次 若触发了touchmove 则click就不会触发
        > 和click等事件一样 touch事件也是有事件对象的
        > touchstart和touchmove通过event.touched来获取手指信息
        > (如触摸的点的位置等信息)
    touchend不能通过event.touched获取
    因为此时手指已经离开了 但是可以通过event.changeTouces获取手指信息
    > 解决点击穿透
    (1.元素阻挡
    2.阻止默认事件 event.preventDefault()
    3.pointer-events CSS3一个新属性
    4.引入fastclick库)
    1. 元素阻挡
        新增一个看不见的元素阻止事件穿透.解决思路基本就是在触发事件的位置动态生成一个新的透明元素,
        这样当300ms之后的click事件来临时,点到的就是这个透明元素,然后再把这个元素删除即可.
        缺点就是写法麻烦,而且有时候用户快速点击的时候,下面元素的事件有可能不会触发,因为此时的透明元素还没有被定时器清理掉.
        弄一个隐藏动画,时间大于300ms,在延迟之后的点击事件来临时,上面的元素还没有消失,这样就不会点到下面的元素了.
    2. 阻止默认事件
        event.preventDefault()
    3. pointer-events
        这是CSS3中的一个属性 其中用的比较多的属性值有auto和none 其他属性基本都是为SVG服务的
    4. fastclick库
        引入fastclick库
22. 微信扫描二维码登陆的实现原理
    > UUID Universally Unique Identifier:通用唯一标识码
    > 二维码
        > 又称二维条码 常见的二维码为QR Code QR全称为Quick Response 是一个近几年在移动设备上很流行的一种编码方式 它比传统的Bar Code条形码能存更多信息 也能表示更多数据类型
    > 移动端基于token的认证机制 
        登陆时 传入账号 密码 手机的设备信息 在服务端验证账号 密码正确后 服务端会做两件事
    1. 将账号与设备关联起来 某种意义上 设备信息就代表着账号
    2. 生成一个token令牌 并将token与账号 设备关联 类似key/value token作为key 账号设备信息作为value 持久化在磁盘上
    将 token 返回给移动端，移动端将 token 存入在本地，往后移动端都通过 token 访问服务端 API ，当然除了 token 之外，还需要携带设备信息，因为 token 可能会被劫持。带上设备信息之后，就算 token 被劫持也没有关系，因为设备信息是唯一的。
    > 二维码扫描登陆的原理
    > 扫码登录可分为三个阶段
    > (待扫描/已扫描待确认/已确认)
    - 待扫描(PC端与服务端交互)
        > 二维码生成阶段 这个计算和移动端没有关系 是PC端和服务端交互过程 PC端携带设备信息向服务端发起生成二维码请求
        > 服务器端会生成唯一的二维码ID 可以理解为UUID 并将二维码ID跟PC设备信息关联起来
        
        > PC端接收到二维码ID后 将二维码ID以二维码形式展示 等待移动端扫码 
        > 此时PC端会开启一个定时器 轮询查询二维码状态 如果移动端未扫描 则一段时间后 二维码失效
    - 已扫描待确认(移动端与服务端交互)
        > PC端登录微信时 手机扫码后 PC端的二维码会变成已扫码 请在手机端确认 这个阶段是移动端跟服务端交互的过程
        - 首先移动端扫描二维码 获取二维码ID 然后将手机端登录的信息凭证(token)和二维码ID作为参数发送给服务端 此时手机一定是登录的 不存在没登录的情况
        - 服务端结束请求后 会将token与二维码ID关联 
        - 关联原因 使用微信时 移动端退出 PC端也需要退出 然后生成一个一次性的token 这个token会返回给移动 端 一次性token用作确认时的凭证
        - PC端的定时器 会轮循到二维码状态已经发生改变 会将PC端的二维码更新为已扫描请确认 
    - 已确认
        - 扫码登录的最后阶段 移动端携带上一步骤中获取的临时token 确认登录 服务端校对完成后会更新二维码状态 并给PC端生成一个正式的token 后续PC端就是持有这个token访问服务端
        - PC端的定时器 轮循到二维码状态未登录状态 并且会获取到生成的token 完成登录 后续访问都基于token完成
        - 在此服务器端会和手机端一样 维护着token和二维码 PC设备信息 账号信息
    到此，二维码扫描登录原理就差不多了，二维码扫描登录在原理上不难理解，跟 OAuth2.0 有一丝的相似之处，但是实现起来可能就比较复杂。                
23. 移动端高清方案 解决图片模糊问题 1px细线问题 
    > 物理像素 设备独立像素 设备像素比
    - 在CSS中我们一般使用px作为单位 CSS样式里面的px和物理像素并不是相等的
    - CSS中的像素只是一个抽象的单位，在不同的设备或不同的环境中，CSS中的1px所代表的物理像素是不同的
    - PC端，CSS的1px一般对应着电脑屏幕的1个物理像素
    - 移动端，CSS的1px等于几个物理像素是和屏幕像素密度有关的。
    > pixel[piksl]像素
    1. 物理像素(physical pixel)
        > 物理像素又被称为设备像素、设备物理像素，它是显示器（电脑、手机屏幕）最小的物理显示单位，每个物理像素由颜色值和亮度值组成。所谓的一倍屏、二倍屏(Retina)、三倍屏，指的是设备以多少物理像素来显示一个CSS像素，也就是说，多倍屏以更多更精细的物理像素点来显示一个CSS像素点
        > 在普通屏幕下1个CSS像素对应1个物理像素，而在Retina屏幕下，1个CSS像素对应的却是4个物理像素（参照下文田字示意图理解）
    2. 设备独立像素(device-independent pixel)CSS像素
        > 设备独立像素又被称为CSS像素，是我们写CSS时所用的像素，它是一个抽像的单位，主要使用在浏览器上，用来精确度量Web页面上的内容
    3. 设备像素比(device pixel ratio)dpr
        > 设备像素比简称为dpr，定义了物理像素和设备独立像素的对应关系：设备像素比 ＝ 物理像素 / 设备独立像素。
        > CSS的1px等于几个物理像素，除了和屏幕像素密度dpr有关，还和用户缩放有关系。例如，当用户把页面放大一倍，那么CSS中1px所代表的物理像素也会增加一倍；反之把页面缩小一倍，CSS中1px所代表的物理像素也会减少一倍。
    4. viewport 视区
        > viewport就是设备上用来显示网页的那一块区域，但viewport又不局限于浏览器可视区域的大小，它可能比浏览器的可视区域要大，也可能比浏览器的可视区域要小。在默认情况下，一般来讲，移动设备上的viewport都是要大于浏览器可视区域的，这是因为考虑到移动设备的分辨率相对于桌面电脑来说都比较小，所以为了能在移动设备上正常显示那些传统的为桌面浏览器设计的网站，移动设备上的浏览器都会把自己默认的viewport设为980px或1024px（也可能是其它值，这个是由设备自己决定的），但带来的后果就是浏览器会出现横向滚动条，因为浏览器可视区域的宽度是比这个默认的viewport的宽度要小的。
    > 明确三种不同的viewport视口
    1. visual viewport 可见视口，指屏幕宽度
        > 获取屏幕宽度(visual viewport)的尺寸：window. innerWidth/Height
    2. layout viewport 布局视口，指DOM宽度
        > 获取DOM宽度(layout viewport)的尺寸：document. documentElement. clientWidth/Height
    3. ideal viewport 理想适口，使布局视口就是可见视口即为理想适口
        > 设置理想视口ideal viewport：
        <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
        > 该meta标签的作用是让layout viewport的宽度等于visual viewport的宽度，同时不允许用户手动缩放，从而达到理想视口。
        meta[name="viewport"]里各参数的含义为：
        - width: 设置layout viewport 的宽度，为一个正整数，或字符串”width-device”。
        - initial-scale: 设置页面的初始缩放值，为一个数字，可以带小数。
        - minimum-scale: 允许用户的最小缩放值，为一个数字，可以带小数。
        - maximum-scale: 允许用户的最大缩放值，为一个数字，可以带小数。
        > height: 设置layout viewport 的高度，这个属性对我们并不重要，很少使用。
        > user-scalable:是否允许用户进行缩放，值为“no”或“yes”。            
    > rem适配方案
    1. 用JS设置rem基准值
    2. 用密集的媒体查询设置font-size
    3. 用vw设置font-size
    
    > 图片模糊问题
    1. (多倍图片)
    2. (不同的dpr下 加载不同尺寸的图片 可用CSS媒体查询 JS条件判断)
        一个位图像素是栅格图像(如：png, jpg, gif等)最小的数据单元。每一个位图像素都包含着一些自身的显示信息(如：显示位置，颜色值，透明度等)。理论上，1个位图像素对应于1个物理像素，图片才能得到完美清晰的展示。对于dpr=2的Retina屏幕而言，1个位图像素对应于4个物理像素，由于单个位图像素不可以再进一步分割，所以只能就近取色，导致图片看起来比较模糊，如下图。

        对于图片模糊问题，比较好的方案就是用多倍图片(@2x)。如：一个200×300(CSS pixel)的img标签，对于dpr=2的屏幕，用400×600的图片，如此一来，位图像素点个数就是原来的4倍，在Retina屏幕下，位图像素点个数就可以跟物理像素点个数形成 1 : 1的比例，图片自然就清晰了。

        最好的解决办法是：不同的dpr下，加载不同的尺寸的图片。不管是通过CSS媒体查询，还是通过JS条件判断都是可以的。
    
    > 1px细线问题(设备独立像素和物理像素是不同的)
    > 在上文我们已经知道，CSS像素为1px宽的直线，对应的物理像素是不同的，可能是2px或者3px,而设计师想要的1px宽的直线,其实就是1物理像素宽
    1. 媒体查询根据dpr用 伪元素+transform对边框进行缩放 构建一个伪元素 border为1px 再以transform缩放到50% 
    2. 用JS根据屏幕尺寸和dpr精确地设置不同屏幕所应有的rem基准值和initial-scale缩放值 JS计算rem基准值和viewport缩放值








